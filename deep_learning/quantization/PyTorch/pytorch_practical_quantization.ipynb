{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Quantization in PyTorch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUNDAMENTALS OF QUANTIZATION\n",
    "\n",
    "Quantization has roots in information compression; in deep networks it refers to reducing the numerical precision of its weights and/or activations.\n",
    "\n",
    "Overparameterized DNNs have more degrees of freedom and this makes them good candidates for information compression. When you quantize a model, two things generally happen - the model gets smaller and runs with better efficiency. \n",
    "\n",
    "- Hardware vendors explicitly allow for faster processing of 8-bit data (than 32-bit data) resulting in higher throughput. \n",
    "- A smaller model has lower memory footprint and power consumption, crucial for deployment at the edge."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping function\n",
    "\n",
    "The mapping function is what you might guess - a function that maps values from floating-point to integer space. A commonly used mapping function is a linear transformation given by:\n",
    "\n",
    "$$Q(r)=round(r/S + Z)$$\n",
    "\n",
    "where `r` is the input and `S` are `Z` `quantization parameters`.\n",
    "\n",
    "To reconvert to floating point space, the inverse function is given by:\n",
    "\n",
    "$$\\hat r=(Q(r) - Z)*S$$\n",
    "\n",
    "$\\hat r \\neq r$, and their difference constitutes the quantization error."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantization Parameters\n",
    "\n",
    "The mapping function is parameterized by the scaling factor `S` and zero-point `Z`.\n",
    "\n",
    " `S` is simply the ratio of the input range to the output range:\n",
    "\n",
    " $$ S = \\dfrac {\\beta - \\alpha} {\\beta_q - \\alpha_q}$$\n",
    "\n",
    "where [$\\alpha$, $\\beta$] is the clipping range of the input, i.e. the boundaries of permissible inputs. [$\\alpha_q$, $\\beta_q$] is the range in quantized output space that it is mapped to. For 8-bit quantization, the output range:\n",
    "$$ \\beta_q - \\alpha_q <= (2^8 - 1)$$\n",
    "\n",
    "`Z` acts as a bias to ensure that a 0 in the input space maps perfectly to a 0 in the quantized space:\n",
    "$$Z=-(\\dfrac {\\alpha}{S} - \\alpha_q)$$ "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibration\n",
    "\n",
    "The process of choosing the input clipping range is known as calibration. The simplest technique (also the default in PyTorch) is to record the running mininmum and maximum values and assign them to $\\alpha$ and $\\beta$. `TensorRT` also uses entropy minimization (KL divergence), mean-square-error minimization, or percentiles of the input range.\n",
    "\n",
    "In PyTorch, `Observer` modules collect statistics on the input values and calculate the qparams `S`, `Z`. Different calibration schemes result in different quantized outputs, and it’s best to empirically verify which scheme works best for your application and architecture (more on that later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[-1.3661,  0.6686, -0.7628, -0.1713],\n",
      "        [ 0.5461, -0.9687,  0.5894, -0.1433],\n",
      "        [ 0.0744,  1.8963, -0.9171,  0.0334]]), tensor([[ 0.3307, -1.0928, -0.8456,  1.2337],\n",
      "        [ 0.6180, -1.6796, -0.9699,  0.8957],\n",
      "        [ 0.5770, -1.1889,  0.9793,  1.6308]])]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.quantization.observer import MinMaxObserver, MovingAverageMinMaxObserver, HistogramObserver\n",
    "\n",
    "C, L = 3, 4\n",
    "normal = torch.distributions.normal.Normal(0, 1)\n",
    "inputs = [normal.sample((C, L)), normal.sample((C, L))]\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxObserver (tensor([0.0185]), tensor([152], dtype=torch.int32))\n",
      "MovingAverageMinMaxObserver (tensor([0.0139]), tensor([137], dtype=torch.int32))\n",
      "HistogramObserver (tensor([0.0128]), tensor([159], dtype=torch.int32))\n"
     ]
    }
   ],
   "source": [
    "observers = [MinMaxObserver(), MovingAverageMinMaxObserver(), HistogramObserver()]\n",
    "for obs in observers:\n",
    "  for x in inputs:\n",
    "    obs(x)\n",
    "  print(obs.__class__.__name__, obs.calculate_qparams())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affine and Symmetric Quantization Schemes\n",
    "\n",
    "__Affine or asymmetric quantization__ schemes assign the input range to the min and max observed values. Affine schemes generally offer tighter clipping ranges and are useful for quantizing non-negative activations (you don’t need the input range to contain negative values if your input tensors are never negative). The range is calculated as $\\alpha=min(r)$, $\\beta=max(r)$. Affine quantization leads to more computationally expensive inference when used for weight tensors.\n",
    "\n",
    "__Symmetric quantization__ schemes center the input range around 0, eliminating the need to calculate a zero-point offset. The range is calculated as:\n",
    "\n",
    "$$ -\\alpha = \\beta = max(|max(r)|, |min(r)|)$$\n",
    "\n",
    " For skewed signals (like non-negative activations) this can result in bad quantization resolution because the clipping range includes values that never show up in the input.\n",
    "\n",
    " In PyTorch, you can specify affine or symmetric schemes while initializing the Observer. Note that not all observers support both schemes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qscheme: torch.per_tensor_affine | (tensor([0.0128]), tensor([107], dtype=torch.int32))\n",
      "Qscheme: torch.per_tensor_symmetric | (tensor([0.0149]), tensor([128]))\n"
     ]
    }
   ],
   "source": [
    "for qscheme in [torch.per_tensor_affine, torch.per_tensor_symmetric]:\n",
    "  obs = MovingAverageMinMaxObserver(qscheme=qscheme)\n",
    "  for x in inputs:\n",
    "    obs(x)\n",
    "  print(f\"Qscheme: {qscheme} | {obs.calculate_qparams()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per-Tensor and Per-Channel Quantization Schemes\n",
    "\n",
    "Quantization parameters can be calculated for the layer’s entire weight tensor as a whole, or separately for each channel. In per-tensor, the same clipping range is applied to all the channels in a layer\n",
    "\n",
    "<img src=\"pic/per-channel-tensor.svg\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch1.13.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "42be7b6d852b9b2b1a0308f8b9cc6db97febf6d6b1b2a588c6bfd7d771418521"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
