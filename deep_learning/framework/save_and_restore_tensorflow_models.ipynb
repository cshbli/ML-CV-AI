{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Save and Restore Tensorflow Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## What is a Tensorflow Model?\n",
        "\n",
        "After you have trained a neural network, you would want to save it for future use and deploying to production. So, what is a Tensorflow model? Tensorflow model primarily contains the network design or graph and values of the network parameters that we have trained. Hence, Tensorflow model has two main files:\n",
        "\n",
        "### Meta graph\n",
        "This is a protocol buffer which saves the complete Tensorflow graph; i.e. all variables, operations, collections etc. This file has .meta extension.\n",
        "\n",
        "### Checkpoint file\n",
        "This is a binary file which contains all the values of the weights, biases, gradients and all the other variables saved. \n",
        "\n",
        "```\n",
        "Checkpoint    \n",
        "mymodel.ckpt.data-00000-of-00001\n",
        "mymodel.ckpt.index\n",
        "mymodel.ckpt.meta    \n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Saving a Tensorflow model\n",
        "\n",
        "Let’s say, you are training a convolutional neural network for image classification. As a standard practice, you keep a watch on loss and accuracy numbers. Once you see that the network has converged, you can stop the training manually or you will run the training for fixed number of epochs. After the training is done, we want to save all the variables and network graph to a file for future use. So, in Tensorflow, you want to save the graph and values of all the parameters for which we shall be creating an instance of `tf.train.Saver()` class.\n",
        "\n",
        "```\n",
        "saver = tf.train.Saver()\n",
        "```\n",
        "\n",
        "Remember that Tensorflow variables are only alive inside a session. So, you have to save the model inside a session by calling save method on saver object you just created.\n",
        "\n",
        "```\n",
        "saver.save(sess, 'my-test-model')\n",
        "```\n",
        "\n",
        "Here, sess is the session object, while ‘my-test-model’ is the name you want to give your model. Let’s see a complete example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "'my_test_model'"
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "w1 = tf.Variable(tf.random_normal(shape=[2]), name='w1')\n",
        "w2 = tf.Variable(tf.random_normal(shape=[5]), name='w2')\n",
        "\n",
        "saver = tf.train.Saver()\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "saver.save(sess, 'my_test_model')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we are saving the model after 1000 iterations, we shall call save by passing the step count:\n",
        "\n",
        "```\n",
        "saver.save(sess, 'my_test_model',global_step=1000)\n",
        "```\n",
        "\n",
        "This will just append ‘-1000’ to the model name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "'my_test_model-1000'"
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "w1 = tf.Variable(tf.random_normal(shape=[2]), name='w1')\n",
        "w2 = tf.Variable(tf.random_normal(shape=[5]), name='w2')\n",
        "\n",
        "saver = tf.train.Saver()\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "saver.save(sess, 'my_test_model', global_step=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s say, while training, we are saving our model after every 1000 iterations, so .meta file is created the first time(on 1000th iteration) and we don’t need to recreate the .meta file each time(so, we don’t save the .meta file at 2000, 3000.. or any other iteration). We only save the model for further iterations, as the graph will not change. Hence, when we don’t want to write the meta-graph we use this:\n",
        "\n",
        "```\n",
        "saver.save(sess, 'my-model', global_step=step, write_meta_graph=False)\n",
        "```\n",
        "\n",
        "If you want to keep only 4 latest models and want to save one model after every 2 hours during training you can use max_to_keep and keep_checkpoint_every_n_hours like this.\n",
        "\n",
        "```\n",
        "#saves a model every 2 hours and maximum 4 latest models are saved.\n",
        "saver = tf.train.Saver(max_to_keep=4, keep_checkpoint_every_n_hours=2)\n",
        "```\n",
        "\n",
        "<b>Note, if we don’t specify anything in the tf.train.Saver(), it saves all the variables</b>. What if, we don’t want to save all the variables and just some of them. We can specify the variables/collections we want to save. While creating the tf.train.Saver instance we pass it a list or a dictionary of variables that we want to save. Let’s look at an example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "'my_test_model-1000'"
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "w1 = tf.Variable(tf.random_normal(shape=[2]), name='w1')\n",
        "w2 = tf.Variable(tf.random_normal(shape=[5]), name='w2')\n",
        "\n",
        "saver = tf.train.Saver([w1,w2])\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "saver.save(sess, 'my_test_model', global_step=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false
      },
      "source": [
        "## Importing a pre-trained model\n",
        "\n",
        "If you want to use someone else’s pre-trained model for fine-tuning, there are two things you need to do:\n",
        "\n",
        "### Create the network:\n",
        "You can create the network by writing python code to create each and every layer manually as the original model. However, if you think about it, we had saved the network in `.meta` file which we can use to recreate the network using `tf.train.import()` function like this: \n",
        "\n",
        "```\n",
        "saver = tf.train.import_meta_graph('my_test_model-1000.meta')\n",
        "```\n",
        "\n",
        "Remember, import_meta_graph appends the network defined in `.meta` file to the current graph. So, this will create the graph/network for you but we still need to load the value of the parameters that we had trained on this graph.\n",
        "\n",
        "### Load the parameters:\n",
        "We can restore the parameters of the network by calling restore on this saver which is an instance of `tf.train.Saver()` class.\n",
        "\n",
        "```\n",
        "with tf.Session() as sess:\n",
        "  new_saver = tf.train.import_meta_graph('my_test_model-1000.meta')\n",
        "  new_saver.restore(sess, tf.train.latest_checkpoint('./'))\n",
        "```  \n",
        "\n",
        "After this, the value of tensors like w1 and w2 has been restored and can be accessed:\n",
        "\n",
        "```\n",
        "with tf.Session() as sess:    \n",
        "    saver = tf.train.import_meta_graph('my-model-1000.meta')\n",
        "    saver.restore(sess,tf.train.latest_checkpoint('./'))\n",
        "    print(sess.run('w1:0'))\n",
        "#Model has been restored. Above statement will print the saved value of w1.\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false
      },
      "source": [
        "### Working with restored models\n",
        "\n",
        "Now that you have understood how to save and restore Tensorflow models, Let’s develop a practical guide to restore any pre-trained model and use it for prediction, fine-tuning or further training. Whenever you are working with Tensorflow, you define a graph which is fed examples(training data) and some hyperparameters like learning rate, global step etc. It’s a standard practice to feed all the training data and hyperparameters using placeholders. Let’s build a small network using placeholders and save it. Note that when the network is saved, values of the placeholders are not saved."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "24.0\n"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "'my_test_model-1000'"
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "tf.reset_default_graph()\n",
        "\n",
        "# Prepare to feed input, i.e. feed_dict and placeholders\n",
        "w1 = tf.placeholder(\"float\", name=\"w1\")\n",
        "w2 = tf.placeholder(\"float\", name=\"w2\")\n",
        "b1 = tf.Variable(2.0, name=\"bias\")\n",
        "feed_dict ={w1:4, w2:8}\n",
        "\n",
        "#Define a test operation that we will restore\n",
        "w3 = tf.add(w1,w2)\n",
        "w4 = tf.multiply(w3,b1,name=\"op_to_restore\")\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "#Create a saver object which will save all the variables\n",
        "saver = tf.train.Saver()\n",
        "\n",
        "#Run the operation by feeding input\n",
        "print(sess.run(w4, feed_dict))\n",
        "#Prints 24 which is sum of (w1+w2)*b1 \n",
        "\n",
        "#Now, save the graph\n",
        "saver.save(sess, 'my_test_model',global_step=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, when we want to restore it, we not only have to restore the graph and weights, but also prepare a new feed_dict that will feed the new training data to the network. We can get reference to these saved operations and placeholder variables via `graph.get_tensor_by_name()` method.\n",
        "\n",
        "```\n",
        "# How to access saved variable/Tensor/placeholders \n",
        "w1 = graph.get_tensor_by_name(\"w1:0\")\n",
        "\n",
        "# How to access saved operation\n",
        "op_to_restore = graph.get_tensor_by_name(\"op_to_restore:0\")\n",
        "```\n",
        "\n",
        "If we just want to run the same network with different data, you can simply pass the new data via feed_dict to the network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "INFO:tensorflow:Restoring parameters from ./my_test_model-1000\n60.0\n"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "tf.reset_default_graph()\n",
        "\n",
        "sess=tf.Session()    \n",
        "#First let's load meta graph and restore weights\n",
        "saver = tf.train.import_meta_graph('my_test_model-1000.meta')\n",
        "saver.restore(sess,tf.train.latest_checkpoint('./'))\n",
        "\n",
        "# Now, let's access and create placeholders variables and\n",
        "# create feed-dict to feed new data\n",
        "graph = tf.get_default_graph()\n",
        "w1 = graph.get_tensor_by_name(\"w1:0\")\n",
        "w2 = graph.get_tensor_by_name(\"w2:0\")\n",
        "feed_dict ={w1:13.0, w2:17.0}\n",
        "\n",
        "#Now, access the op that you want to run. \n",
        "op_to_restore = graph.get_tensor_by_name(\"op_to_restore:0\")\n",
        "\n",
        "print(sess.run(op_to_restore,feed_dict))\n",
        "#This will print 60 which is calculated \n",
        "#using new values of w1 and w2 and saved value of b1. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "What if you want to add more operations to the graph by adding more layers and then train it. Of course you can do that too. See here:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "INFO:tensorflow:Restoring parameters from ./my_test_model-1000\n120.0\n"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "tf.reset_default_graph()\n",
        "\n",
        "sess=tf.Session()    \n",
        "#First let's load meta graph and restore weights\n",
        "saver = tf.train.import_meta_graph('my_test_model-1000.meta')\n",
        "saver.restore(sess,tf.train.latest_checkpoint('./'))\n",
        "\n",
        "# Now, let's access and create placeholders variables and\n",
        "# create feed-dict to feed new data\n",
        "\n",
        "graph = tf.get_default_graph()\n",
        "w1 = graph.get_tensor_by_name(\"w1:0\")\n",
        "w2 = graph.get_tensor_by_name(\"w2:0\")\n",
        "feed_dict ={w1:13.0,w2:17.0}\n",
        "\n",
        "#Now, access the op that you want to run. \n",
        "op_to_restore = graph.get_tensor_by_name(\"op_to_restore:0\")\n",
        "\n",
        "#Add more to the current graph\n",
        "add_on_op = tf.multiply(op_to_restore,2)\n",
        "\n",
        "print(sess.run(add_on_op,feed_dict))\n",
        "#This will print 120."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "But, can you restore part of the old graph and add-on to that for fine-tuning ? Of-course you can, just access the appropriate operation by `graph.get_tensor_by_name()` method and build graph on top of that."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.6.9 64-bit",
      "language": "python",
      "name": "python36964bit1e1001aa09194e9bb96c94cb914c3517"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9-final"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}