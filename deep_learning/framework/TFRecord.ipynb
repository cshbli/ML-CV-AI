{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TFRecord"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## What is a TFRecord\n",
        "\n",
        "TFRecord is an individual aggregated compact file summing up all the data (present in any format) required during training/testing of a model. This particular file can be transported across multiple systems and is also independent of the model on which it is going to be trained on. The TFRecord file may also contain additional overhead data required to reconstruct the original data which may not have been needed had we trained without TFRecord. Also, in case the dataset is extremely large, we may have to create multiple similar types of TFRecord files.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## How to build a TFRecord\n",
        "\n",
        "Any data in TFRecord has to be stored as either list of bytes or list of float or list of int64 only. Each of these data list entity created has to be wrapped by a Feature class. Next, each of the feature is stored in a key value pair with key corresponding to the title being allotted to each feature. These titles are going to be used later when extracting the data from TFRecord. The dictionary created is passed as input to Features class. Lastly, the features object is passed as input to Example class. Then this example class object is appended into the TFRecord. The above procedure is repeated for every type of data which has to be stored in TFRecord. The code to create TFRecord using simple data is given next."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "data_arr = [\n",
        "    {\n",
        "        'int_data': 108,\n",
        "        'float_data': 2.45,\n",
        "        'str_data': 'String 100',\n",
        "        'float_list_data': [256.78, 13.9]\n",
        "    },\n",
        "    {\n",
        "        'int_data': 37,\n",
        "        'float_data': 84.3,\n",
        "        'str_data': 'String 200',\n",
        "        'float_list_data': [1.34, 843.9, 65.22]\n",
        "    }\n",
        "]\n",
        "\n",
        "def get_example_object(data_record):\n",
        "    # Convert individual data into a list of int64 or float or bytes\n",
        "    int_list1 = tf.train.Int64List(value = [data_record['int_data']])\n",
        "    float_list1 = tf.train.FloatList(value = [data_record['float_data']])\n",
        "    # Convert string data into list of bytes\n",
        "    str_list1 = tf.train.BytesList(value = [data_record['str_data'].encode('utf-8')])\n",
        "    float_list2 = tf.train.FloatList(value = data_record['float_list_data'])\n",
        "\n",
        "    # Create a dictionary with above lists individually wrapped in Feature\n",
        "    feature_key_value_pair = {\n",
        "        'int_list1': tf.train.Feature(int64_list = int_list1),\n",
        "        'float_list1': tf.train.Feature(float_list = float_list1),\n",
        "        'str_list1': tf.train.Feature(bytes_list = str_list1),\n",
        "        'float_list2': tf.train.Feature(float_list = float_list2)\n",
        "    }\n",
        "\n",
        "    # Create Features object with above feature dictionary\n",
        "    features = tf.train.Features(feature = feature_key_value_pair)\n",
        "\n",
        "    # Create Example object with features\n",
        "    example = tf.train.Example(features = features)\n",
        "    return example\n",
        "\n",
        "with tf.python_io.TFRecordWriter('example.tfrecord') as tfwriter:\n",
        "    # Iterate through all records\n",
        "    for data_record in data_arr:\n",
        "        example = get_example_object(data_record)\n",
        "\n",
        "        # Append each example into tfrecord\n",
        "        tfwriter.write(example.SerializeToString())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create TFRecord for Images\n",
        "\n",
        "Now that we have basic understanding on how to create a TFRecord for text type of data comprising of dictionaries and lists, let us proceed into adding images. Our [toy dataset](./TFRecordImages) comprises of totally 10 images and two types of classes i.e cats and dogs. The dataset is a mixture of PNG and JPEG type of images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "class GenerateTFRecord:\n",
        "    def __init__(self, labels):\n",
        "        self.labels = labels\n",
        "\n",
        "    def convert_image_folder(self, img_folder, tfrecord_file_name):\n",
        "        # Get all file names of images present in folder\n",
        "        img_paths = os.listdir(img_folder)\n",
        "        img_paths = [os.path.abspath(os.path.join(img_folder, i)) for i in img_paths]\n",
        "\n",
        "        with tf.python_io.TFRecordWriter(tfrecord_file_name) as writer:\n",
        "            for img_path in img_paths:\n",
        "                example = self._convert_image(img_path)\n",
        "                writer.write(example.SerializeToString())\n",
        "\n",
        "    # convert the images to Numpy string, the TFRecord file size is huge\n",
        "    # def _convert_image(self, img_path):\n",
        "    #     label = self._get_label_with_filename(img_path)\n",
        "    #     image_data = mpimg.imread(img_path)\n",
        "    #     # Convert image to string data\n",
        "    #     image_str = image_data.tostring()\n",
        "    #     # Store shape of image for reconstruction purposes\n",
        "    #     img_shape = image_data.shape\n",
        "    #     # Get filename\n",
        "    #     filename = os.path.basename(img_path)\n",
        "        \n",
        "    #     example = tf.train.Example(features = tf.train.Features(feature = {\n",
        "    #         'filename': tf.train.Feature(bytes_list = tf.train.BytesList(value = [filename.encode('utf-8')])),\n",
        "    #         'rows': tf.train.Feature(int64_list = tf.train.Int64List(value = [img_shape[0]])),\n",
        "    #         'cols': tf.train.Feature(int64_list = tf.train.Int64List(value = [img_shape[1]])),\n",
        "    #         'channels': tf.train.Feature(int64_list = tf.train.Int64List(value = [img_shape[2]])),\n",
        "    #         'image': tf.train.Feature(bytes_list = tf.train.BytesList(value = [image_str])),\n",
        "    #         'label': tf.train.Feature(int64_list = tf.train.Int64List(value = [label]))\n",
        "    #     }))\n",
        "    #     return example\n",
        "\n",
        "    def _convert_image(self, img_path):\n",
        "        label = self._get_label_with_filename(img_path)\n",
        "        img_shape = mpimg.imread(img_path).shape\n",
        "        filename = os.path.basename(img_path)\n",
        "\n",
        "        # Read image data in terms of bytes\n",
        "        with tf.gfile.GFile(img_path, 'rb') as fid:\n",
        "            image_data = fid.read()\n",
        "\n",
        "        example = tf.train.Example(features = tf.train.Features(feature = {\n",
        "            'filename': tf.train.Feature(bytes_list = tf.train.BytesList(value = [filename.encode('utf-8')])),\n",
        "            'rows': tf.train.Feature(int64_list = tf.train.Int64List(value = [img_shape[0]])),\n",
        "            'cols': tf.train.Feature(int64_list = tf.train.Int64List(value = [img_shape[1]])),\n",
        "            'channels': tf.train.Feature(int64_list = tf.train.Int64List(value = [img_shape[2]])),\n",
        "            'image': tf.train.Feature(bytes_list = tf.train.BytesList(value = [image_data])),\n",
        "            'label': tf.train.Feature(int64_list = tf.train.Int64List(value = [label])),\n",
        "        }))\n",
        "        return example        \n",
        "\n",
        "    def _get_label_with_filename(self, filename):\n",
        "        basename = os.path.basename(filename).split('.')[0]\n",
        "        basename = basename.split('_')[0]        \n",
        "        return self.labels[basename]\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    labels = {'cat': 0, 'dog': 1}\n",
        "    t = GenerateTFRecord(labels)\n",
        "    t.convert_image_folder('TFRecordImages', 'images.tfrecord')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now the size of our images.tfrecord file is 1.2 MB which is almost the same size of individual images summed up."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reduce TFRecord size further\n",
        "\n",
        "Now, let us try to bring the TFRecord size further down. PNG images tend to capture more information with sharper edge details. This comes at a cost of increased storage size of image. Converting to JPEG images will infinitesimally blur your image but it will reward you with measurable amount of storage size reduction. Tensorflow also provides you with amount of quality you wish to retain when you are doing the conversion."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "class GenerateTFRecord:\n",
        "    def __init__(self, labels):\n",
        "        self.labels = labels\n",
        "        self._create_graph()\n",
        "\n",
        "    def convert_image_folder(self, img_folder, tfrecord_file_name):\n",
        "        # Get all file names of images present in folder\n",
        "        img_paths = os.listdir(img_folder)\n",
        "        img_paths = [os.path.abspath(os.path.join(img_folder, i)) for i in img_paths]\n",
        "\n",
        "        with tf.python_io.TFRecordWriter(tfrecord_file_name) as writer:\n",
        "            for img_path in img_paths:\n",
        "                example = self._convert_image(img_path)\n",
        "                writer.write(example.SerializeToString())        \n",
        "\n",
        "    # Create graph to convert PNG image data to JPEG data\n",
        "    def _create_graph(self):\n",
        "        tf.reset_default_graph()\n",
        "        self.png_img_pl = tf.placeholder(tf.string)\n",
        "        png_enc = tf.image.decode_png(self.png_img_pl, channels = 3)\n",
        "        # Set how much quality of image you would like to retain while conversion\n",
        "        self.png_to_jpeg = tf.image.encode_jpeg(png_enc, format = 'rgb', quality = 100)\n",
        "\n",
        "    def _is_png_image(self, filename):\n",
        "        ext = os.path.splitext(filename)[1].lower()\n",
        "        return ext == '.png'\n",
        "\n",
        "    # Run graph to convert PNG image data to JPEG data\n",
        "    def _convert_png_to_jpeg(self, img):\n",
        "        sess = tf.Session()\n",
        "        return sess.run(self.png_to_jpeg, feed_dict = {self.png_img_pl: img})\n",
        "\n",
        "    def _convert_image(self, img_path):\n",
        "        label = self._get_label_with_filename(img_path)\n",
        "        img_shape = mpimg.imread(img_path).shape\n",
        "        filename = os.path.basename(img_path).split('.')[0]\n",
        "\n",
        "        # Read image data in terms of bytes\n",
        "        with tf.gfile.GFile(img_path, 'rb') as fid:\n",
        "            image_data = fid.read()\n",
        "\n",
        "            # Encode PNG data to JPEG data\n",
        "            if self._is_png_image(img_path):\n",
        "                image_data = self._convert_png_to_jpeg(image_data)\n",
        "\n",
        "        example = tf.train.Example(features = tf.train.Features(feature = {\n",
        "            'filename': tf.train.Feature(bytes_list = tf.train.BytesList(value = [filename.encode('utf-8')])),\n",
        "            'rows': tf.train.Feature(int64_list = tf.train.Int64List(value = [img_shape[0]])),\n",
        "            'cols': tf.train.Feature(int64_list = tf.train.Int64List(value = [img_shape[1]])),\n",
        "            'channels': tf.train.Feature(int64_list = tf.train.Int64List(value = [3])),\n",
        "            'image': tf.train.Feature(bytes_list = tf.train.BytesList(value = [image_data])),\n",
        "            'label': tf.train.Feature(int64_list = tf.train.Int64List(value = [label])),\n",
        "        }))\n",
        "        return example\n",
        "\n",
        "    def _get_label_with_filename(self, filename):\n",
        "        basename = os.path.basename(filename).split('.')[0]\n",
        "        basename = basename.split('_')[0]        \n",
        "        return self.labels[basename]\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    labels = {'cat': 0, 'dog': 1}\n",
        "    t = GenerateTFRecord(labels)\n",
        "    t.convert_image_folder('TFRecordImages', 'images.tfrecord')        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, maintaining 100 percent of encoding quality, we have reduced the earlier TFRecord file of 1.2 MB to 579.5 KB."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extracting data from TFRecord\n",
        "\n",
        "Now that our TFRecords are ready, it is time to send them into training pipeline. The first step is to initialize TFRecordDataset with all the TFRecord file paths. After that, we have to extract the various features present in the TFRecords. We specify the various keys used during TFRecord formation earlier in this step. If we know beforehand what is the number of items present in the list of bytes or float or int64 for each data record, we can make use of FixedLenFeature, or else, we make use of VarLenFeature class. Next, the API parse_single_example extracts a dictionary object of each data record. Let us look into the extraction procedure of the TFRecord created earlier with simple text dictionary data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "WARNING:tensorflow:From <ipython-input-14-d6b66d6a720d>:18: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n{'float_list2': SparseTensorValue(indices=array([[0],\n       [1]]), values=array([256.78,  13.9 ], dtype=float32), dense_shape=array([2])), 'float_list1': 2.45, 'int_list1': 108, 'str_list1': b'String 100'}\n{'float_list2': SparseTensorValue(indices=array([[0],\n       [1],\n       [2]]), values=array([  1.34, 843.9 ,  65.22], dtype=float32), dense_shape=array([3])), 'float_list1': 84.3, 'int_list1': 37, 'str_list1': b'String 200'}\n"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def extract_fn(data_record):\n",
        "    features = {\n",
        "        # Extract features using the keys set during creation\n",
        "        'int_list1': tf.FixedLenFeature([], tf.int64),\n",
        "        'float_list1': tf.FixedLenFeature([], tf.float32),\n",
        "        'str_list1': tf.FixedLenFeature([], tf.string),\n",
        "        # If size is different of different records, use VarLenFeature \n",
        "        'float_list2': tf.VarLenFeature(tf.float32)\n",
        "    }\n",
        "    sample = tf.parse_single_example(data_record, features)\n",
        "    return sample\n",
        "\n",
        "# Initialize all tfrecord paths\n",
        "dataset = tf.data.TFRecordDataset(['example.tfrecord'])\n",
        "dataset = dataset.map(extract_fn)\n",
        "iterator = dataset.make_one_shot_iterator()\n",
        "next_element = iterator.get_next()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    try:\n",
        "        while True:\n",
        "            data_record = sess.run(next_element)\n",
        "            print(data_record)\n",
        "    except:\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extract Images from TFRecord\n",
        "\n",
        "We extend the same concept of extraction of simple TFRecord files to extract images from it as well. With the help of tf.image.decode_image API, we can decode the image present in any format. As a precautionary measure, we verify whether the shape of the decoded image matches with the stored overhead data of rows, cols and channels in TFRecord. Let us dive into the code of extraction of images from TFRecord."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Save path =  /data/Projects/MachineLearning-ComputerVision-DataScience/framework/ExtractedImages/dog_2 , Label =  1\nSave path =  /data/Projects/MachineLearning-ComputerVision-DataScience/framework/ExtractedImages/cat_3 , Label =  0\nSave path =  /data/Projects/MachineLearning-ComputerVision-DataScience/framework/ExtractedImages/dog_0 , Label =  1\nSave path =  /data/Projects/MachineLearning-ComputerVision-DataScience/framework/ExtractedImages/dog_4 , Label =  1\nSave path =  /data/Projects/MachineLearning-ComputerVision-DataScience/framework/ExtractedImages/cat_4 , Label =  0\nSave path =  /data/Projects/MachineLearning-ComputerVision-DataScience/framework/ExtractedImages/dog_3 , Label =  1\nSave path =  /data/Projects/MachineLearning-ComputerVision-DataScience/framework/ExtractedImages/cat_2 , Label =  0\nSave path =  /data/Projects/MachineLearning-ComputerVision-DataScience/framework/ExtractedImages/dog_1 , Label =  1\nSave path =  /data/Projects/MachineLearning-ComputerVision-DataScience/framework/ExtractedImages/cat_0 , Label =  0\nSave path =  /data/Projects/MachineLearning-ComputerVision-DataScience/framework/ExtractedImages/cat_1 , Label =  0\n"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import shutil\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "\n",
        "class TFRecordExtractor:\n",
        "    def __init__(self, tfrecord_file):\n",
        "        self.tfrecord_file = os.path.abspath(tfrecord_file)\n",
        "\n",
        "    def _extract_fn(self, tfrecord):\n",
        "        # Extract features using the keys set during creation\n",
        "        features = {\n",
        "            'filename': tf.FixedLenFeature([], tf.string),\n",
        "            'rows': tf.FixedLenFeature([], tf.int64),\n",
        "            'cols': tf.FixedLenFeature([], tf.int64),\n",
        "            'channels': tf.FixedLenFeature([], tf.int64),\n",
        "            'image': tf.FixedLenFeature([], tf.string),\n",
        "            'label': tf.FixedLenFeature([], tf.int64)\n",
        "        }\n",
        "\n",
        "        # Extract the data record\n",
        "        sample = tf.parse_single_example(tfrecord, features)\n",
        "\n",
        "        image = tf.image.decode_image(sample['image'])        \n",
        "        img_shape = tf.stack([sample['rows'], sample['cols'], sample['channels']])\n",
        "        label = sample['label']\n",
        "        filename = sample['filename']\n",
        "        return [image, label, filename, img_shape]        \n",
        "\n",
        "    def extract_image(self):\n",
        "        # Create folder to store extracted images\n",
        "        folder_path = './ExtractedImages'\n",
        "        shutil.rmtree(folder_path, ignore_errors = True)\n",
        "        os.mkdir(folder_path)\n",
        "\n",
        "        # Pipeline of dataset and iterator \n",
        "        dataset = tf.data.TFRecordDataset([self.tfrecord_file])\n",
        "        dataset = dataset.map(self._extract_fn)\n",
        "        iterator = dataset.make_one_shot_iterator()\n",
        "        next_image_data = iterator.get_next()\n",
        "\n",
        "        with tf.Session() as sess:\n",
        "            sess.run(tf.global_variables_initializer())\n",
        "\n",
        "            try:\n",
        "                # Keep extracting data till TFRecord is exhausted\n",
        "                while True:\n",
        "                    image_data = sess.run(next_image_data)\n",
        "\n",
        "                    # Check if image shape is same after decoding\n",
        "                    if not np.array_equal(image_data[0].shape, image_data[3]):\n",
        "                        print('Image {} not decoded properly'.format(image_data[2]))\n",
        "                        continue\n",
        "                        \n",
        "                    save_path = os.path.abspath(os.path.join(folder_path, image_data[2].decode('utf-8')))\n",
        "                    mpimg.imsave(save_path, image_data[0])\n",
        "                    print('Save path = ', save_path, ', Label = ', image_data[1])\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    t = TFRecordExtractor('./images.tfrecord')\n",
        "    t.extract_image()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.6.9 64-bit",
      "language": "python",
      "name": "python36964bit1e1001aa09194e9bb96c94cb914c3517"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9-final"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}