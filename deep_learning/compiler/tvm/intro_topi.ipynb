{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nIntroduction to TOPI\n====================\n**Author**: `Ehsan M. Kermani <https://github.com/ehsanmok>`_\n\nThis is an introductory tutorial to TVM Operator Inventory (TOPI).\nTOPI provides numpy-style generic operations and schedules with higher abstractions than TVM.\nIn this tutorial, we will see how TOPI can save us from writing boilerplates code in TVM.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import, print_function\n",
        "\n",
        "import tvm\n",
        "from tvm import te\n",
        "import topi\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Basic example\n-------------\nLet's revisit the sum of rows operation (equivalent to :code:`B = numpy.sum(A, axis=1)`') \\\nTo compute the sum of rows of a two dimensional TVM tensor A, we should\nspecify the symbolic operation as well as schedule as follows\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n = te.var(\"n\")\n",
        "m = te.var(\"m\")\n",
        "A = te.placeholder((n, m), name='A')\n",
        "k = te.reduce_axis((0, m), \"k\")\n",
        "B = te.compute((n,), lambda i: te.sum(A[i, k], axis=k), name=\"B\")\n",
        "s = te.create_schedule(B.op)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and to examine the IR code in human readable format, we can do\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "// attr [B] storage_scope = \"global\"\nallocate B[float32 * n]\nproduce B {\n  for (i, 0, n) {\n    B[i] = 0f\n    for (k, 0, m) {\n      B[i] = (B[i] + A[((i*stride) + (k*stride))])\n    }\n  }\n}\n\n"
        }
      ],
      "source": [
        "print(tvm.lower(s, [A], simple_mode=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "However, for such a common operation we had to define the reduce axis ourselves as well as explicit computation with\n:code:`te.compute`. Imagine for more complicated operations how much details we need to provide.\nFortunately, we can replace those two lines with simple :code:`topi.sum` much like :code:`numpy.sum`\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "// attr [A_red] storage_scope = \"global\"\nallocate A_red[float32 * n]\nproduce A_red {\n  for (ax0, 0, n) {\n    A_red[ax0] = 0f\n    for (k1, 0, m) {\n      A_red[ax0] = (A_red[ax0] + A[((ax0*stride) + (k1*stride))])\n    }\n  }\n}\n\n"
        }
      ],
      "source": [
        "C = topi.sum(A, axis=1)\n",
        "ts = te.create_schedule(C.op)\n",
        "print(tvm.lower(ts, [A], simple_mode=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Numpy-style operator overloading\n--------------------------------\nWe can add two tensors using :code:`topi.broadcast_add` that have correct (broadcastable with specific) shapes.\nEven shorter, TOPI provides operator overloading for such common operations. For example,\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x, y = 100, 10\n",
        "a = te.placeholder((x, y, y), name=\"a\")\n",
        "b = te.placeholder((y, y), name=\"b\")\n",
        "c = a + b  # same as topi.broadcast_add\n",
        "d = a * b  # same as topi.broadcast_mul"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Overloaded with the same syntax, TOPI handles broadcasting a primitive (`int`, `float`) to a tensor :code:`d - 3.14`.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generic schedules and fusing operations\n---------------------------------------\nUp to now, we have seen an example of how TOPI can save us from writing explicit computations in lower level API.\nBut it doesn't stop here. Still we did the scheduling as before. TOPI also provides higher level\nscheduling recipes depending on a given context. For example, for CUDA,\nwe can schedule the following series of operations ending with :code:`topi.sum` using only\n:code:`topi.generic.schedule_reduce`\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "// attr [T_divide_red] storage_scope = \"global\"\nallocate T_divide_red[float32 * 1]\nproduce T_divide_red {\n  // attr [iter_var(threadIdx.x, range(min=0, ext=1024), threadIdx.x)] thread_extent = 1024\n  // attr [T_divide_red.rf] storage_scope = \"local\"\n  allocate T_divide_red.rf[float32 * 1]\n  // attr [reduce_temp0] storage_scope = \"local\"\n  allocate reduce_temp0[float32 * 1]\n  produce T_divide_red.rf {\n    T_divide_red.rf[0] = 0f\n    for (k0.k1.fused.k2.fused.outer, 0, 10) {\n      if (likely((((((k0.k1.fused.k2.fused.outer*1024) + threadIdx.x) < 10000) && (((k0.k1.fused.k2.fused.outer*1024) + threadIdx.x) < 10000)) && (((k0.k1.fused.k2.fused.outer*1024) + threadIdx.x) < 10000)))) {\n        T_divide_red.rf[0] = (T_divide_red.rf[0] + (((a[((k0.k1.fused.k2.fused.outer*1024) + threadIdx.x)] + b[floormod(((k0.k1.fused.k2.fused.outer*1024) + threadIdx.x), 100)]) + (a[((k0.k1.fused.k2.fused.outer*1024) + threadIdx.x)]*b[floormod(((k0.k1.fused.k2.fused.outer*1024) + threadIdx.x), 100)]))*0.5f))\n      }\n    }\n  }\n  // attr [comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f])] reduce_scope = reinterpret((uint64)0)\n  tvm_thread_allreduce((uint32)1, T_divide_red.rf[0], (bool)1, reduce_temp0, threadIdx.x)\n  if ((threadIdx.x == 0)) {\n    T_divide_red[0] = reduce_temp0[0]\n  }\n}\n\n"
        }
      ],
      "source": [
        "e = topi.elemwise_sum([c, d])\n",
        "f = e / 2.0\n",
        "g = topi.sum(f)\n",
        "with tvm.target.cuda():\n",
        "    sg = topi.cuda.schedule_reduce(g)\n",
        "    print(tvm.lower(sg, [a, b], simple_mode=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As you can see, scheduled stages of computation have been accumulated and we can examine them by\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[stage(a, 0x3479de0), stage(b, 0x2d33c90), stage(T_add, 0x3bbff50), stage(T_multiply, 0x3b6c620), stage(T_elemwise_sum, 0x3a23b90), stage(T_divide, 0x3b6b240), stage(T_divide_red.rf, 0x3c44220), stage(T_divide_red, 0x3c41040)]\n"
        }
      ],
      "source": [
        "print(sg.stages)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can test the correctness by comparing with :code:`numpy` result as follows\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "func = tvm.build(sg, [a, b, g], 'cuda')\n",
        "ctx = tvm.gpu(0)\n",
        "a_np = np.random.uniform(size=(x, y, y)).astype(a.dtype)\n",
        "b_np = np.random.uniform(size=(y, y)).astype(b.dtype)\n",
        "g_np = np.sum(np.add(a_np + b_np, a_np * b_np) / 2.0)\n",
        "a_nd = tvm.nd.array(a_np, ctx)\n",
        "b_nd = tvm.nd.array(b_np, ctx)\n",
        "g_nd = tvm.nd.array(np.zeros(g_np.shape, dtype=g_np.dtype), ctx)\n",
        "func(a_nd, b_nd, g_nd)\n",
        "tvm.testing.assert_allclose(g_nd.asnumpy(), g_np, rtol=1e-5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "TOPI also provides common neural nets operations such as _softmax_ with optimized schedule\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "// attr [T_softmax_maxelem] storage_scope = \"global\"\nallocate T_softmax_maxelem[float32 * 512]\n// attr [T_softmax_exp] storage_scope = \"global\"\nallocate T_softmax_exp[float32 * 262144]\nproduce T_softmax_maxelem {\n  // attr [iter_var(blockIdx.x, , blockIdx.x)] thread_extent = 512\n  T_softmax_maxelem[blockIdx.x] = -3.40282e+38f\n  for (k, 0, 512) {\n    T_softmax_maxelem[blockIdx.x] = max(T_softmax_maxelem[blockIdx.x], tarray[((blockIdx.x*512) + k)])\n  }\n}\nproduce T_softmax_exp {\n  // attr [iter_var(blockIdx.x, , blockIdx.x)] thread_extent = 512\n  for (i1, 0, 512) {\n    T_softmax_exp[((blockIdx.x*512) + i1)] = exp((tarray[((blockIdx.x*512) + i1)] - T_softmax_maxelem[blockIdx.x]))\n  }\n}\nproduce T_softmax_expsum {\n  // attr [iter_var(blockIdx.x, , blockIdx.x)] thread_extent = 512\n  // attr [T_softmax_expsum.rf] storage_scope = \"local\"\n  allocate T_softmax_expsum.rf[float32 * 1]\n  // attr [reduce_temp0] storage_scope = \"local\"\n  allocate reduce_temp0[float32 * 1]\n  // attr [iter_var(threadIdx.x, range(min=0, ext=64), threadIdx.x)] thread_extent = 64\n  produce T_softmax_expsum.rf {\n    T_softmax_expsum.rf[0] = 0f\n    for (k.outer, 0, 8) {\n      T_softmax_expsum.rf[0] = (T_softmax_expsum.rf[0] + T_softmax_exp[(((blockIdx.x*512) + (k.outer*64)) + threadIdx.x)])\n    }\n  }\n  // attr [comm_reducer(result=[(x + y)], lhs=[x], rhs=[y], identity_element=[0f])] reduce_scope = reinterpret((uint64)0)\n  tvm_thread_allreduce((uint32)1, T_softmax_expsum.rf[0], (bool)1, reduce_temp0, threadIdx.x)\n  if ((threadIdx.x == 0)) {\n    T_softmax_maxelem[blockIdx.x] = reduce_temp0[0]\n  }\n}\nproduce T_softmax_norm {\n  // attr [iter_var(blockIdx.x, , blockIdx.x)] thread_extent = 512\n  // attr [iter_var(threadIdx.x, range(min=0, ext=64), threadIdx.x)] thread_extent = 64\n  for (i1.inner, 0, 8) {\n    T_softmax_exp[(((blockIdx.x*512) + (threadIdx.x*8)) + i1.inner)] = (T_softmax_exp[(((blockIdx.x*512) + (threadIdx.x*8)) + i1.inner)]/T_softmax_maxelem[blockIdx.x])\n  }\n}\n\n"
        }
      ],
      "source": [
        "tarray = te.placeholder((512, 512), name=\"tarray\")\n",
        "softmax_topi = topi.nn.softmax(tarray)\n",
        "with tvm.target.create(\"cuda\"):\n",
        "    sst = topi.cuda.schedule_softmax(softmax_topi)\n",
        "    print(tvm.lower(sst, [tarray], simple_mode=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fusing convolutions\n-------------------\nWe can fuse :code:`topi.nn.conv2d` and :code:`topi.nn.relu` together.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>TOPI functions are all generic functions. They have different implementations\n   for different backends to optimize for performance.\n   For each backend, it is necessary to call them under a target scope for both\n   compute declaration and schedule. TVM will choose the right function to call with\n   the target information.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "collapsed": false,
        "tags": [
          "outputPrepend"
        ]
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": " (compute[12] + (pad_temp.shared[(threadIdx.x + 96)]*placeholder.shared[0]))\n        compute[1] = (compute[1] + (pad_temp.shared[threadIdx.x]*placeholder.shared[1]))\n        compute[3] = (compute[3] + (pad_temp.shared[(threadIdx.x + 16)]*placeholder.shared[1]))\n        compute[5] = (compute[5] + (pad_temp.shared[(threadIdx.x + 32)]*placeholder.shared[1]))\n        compute[7] = (compute[7] + (pad_temp.shared[(threadIdx.x + 48)]*placeholder.shared[1]))\n        compute[9] = (compute[9] + (pad_temp.shared[(threadIdx.x + 64)]*placeholder.shared[1]))\n        compute[11] = (compute[11] + (pad_temp.shared[(threadIdx.x + 80)]*placeholder.shared[1]))\n        compute[13] = (compute[13] + (pad_temp.shared[(threadIdx.x + 96)]*placeholder.shared[1]))\n        produce pad_temp.shared {\n          // attr [iter_var(threadIdx.z, , threadIdx.z)] thread_extent = 1\n          // attr [iter_var(threadIdx.y, , threadIdx.y)] thread_extent = 1\n          // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 16\n          pad_temp.shared[(threadIdx.x*7)] = tvm_if_then_else((((2 <= (blockIdx.y + ry.outer)) && ((blockIdx.y + ry.outer) < 226)) && (1 <= ((blockIdx.x*112) + (threadIdx.x*7)))), placeholder[((((((rc.outer*50176) + (blockIdx.y*224)) + (ry.outer*224)) + (blockIdx.x*112)) + (threadIdx.x*7)) - 449)], 0f)\n          pad_temp.shared[((threadIdx.x*7) + 1)] = tvm_if_then_else(((2 <= (blockIdx.y + ry.outer)) && ((blockIdx.y + ry.outer) < 226)), placeholder[((((((rc.outer*50176) + (blockIdx.y*224)) + (ry.outer*224)) + (blockIdx.x*112)) + (threadIdx.x*7)) - 448)], 0f)\n          pad_temp.shared[((threadIdx.x*7) + 2)] = tvm_if_then_else(((2 <= (blockIdx.y + ry.outer)) && ((blockIdx.y + ry.outer) < 226)), placeholder[((((((rc.outer*50176) + (blockIdx.y*224)) + (ry.outer*224)) + (blockIdx.x*112)) + (threadIdx.x*7)) - 447)], 0f)\n          pad_temp.shared[((threadIdx.x*7) + 3)] = tvm_if_then_else(((2 <= (blockIdx.y + ry.outer)) && ((blockIdx.y + ry.outer) < 226)), placeholder[((((((rc.outer*50176) + (blockIdx.y*224)) + (ry.outer*224)) + (blockIdx.x*112)) + (threadIdx.x*7)) - 446)], 0f)\n          pad_temp.shared[((threadIdx.x*7) + 4)] = tvm_if_then_else(((2 <= (blockIdx.y + ry.outer)) && ((blockIdx.y + ry.outer) < 226)), placeholder[((((((rc.outer*50176) + (blockIdx.y*224)) + (ry.outer*224)) + (blockIdx.x*112)) + (threadIdx.x*7)) - 445)], 0f)\n          pad_temp.shared[((threadIdx.x*7) + 5)] = tvm_if_then_else(((2 <= (blockIdx.y + ry.outer)) && ((blockIdx.y + ry.outer) < 226)), placeholder[((((((rc.outer*50176) + (blockIdx.y*224)) + (ry.outer*224)) + (blockIdx.x*112)) + (threadIdx.x*7)) - 444)], 0f)\n          pad_temp.shared[((threadIdx.x*7) + 6)] = tvm_if_then_else(((2 <= (blockIdx.y + ry.outer)) && ((blockIdx.y + ry.outer) < 226)), placeholder[((((((rc.outer*50176) + (blockIdx.y*224)) + (ry.outer*224)) + (blockIdx.x*112)) + (threadIdx.x*7)) - 443)], 0f)\n        }\n        produce placeholder.shared {\n          // attr [iter_var(threadIdx.z, , threadIdx.z)] thread_extent = 1\n          // attr [iter_var(threadIdx.y, , threadIdx.y)] thread_extent = 1\n          // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 16\n          if (likely((threadIdx.x < 2))) {\n            if (likely((threadIdx.x < 2))) {\n              if (likely((threadIdx.x < 2))) {\n                if (likely((threadIdx.x < 2))) {\n                  if (likely((threadIdx.x < 2))) {\n                    if (likely((threadIdx.x < 2))) {\n                      if (likely((((blockIdx.z*2) + threadIdx.x) < 10))) {\n                        placeholder.shared[threadIdx.x] = placeholder[(((((blockIdx.z*150) + (threadIdx.x*75)) + (rc.outer*25)) + (ry.outer*5)) + 1)]\n                      }\n                    }\n                  }\n                }\n              }\n            }\n          }\n        }\n        compute[0] = (compute[0] + (pad_temp.shared[threadIdx.x]*placeholder.shared[0]))\n        compute[2] = (compute[2] + (pad_temp.shared[(threadIdx.x + 16)]*placeholder.shared[0]))\n        compute[4] = (compute[4] + (pad_temp.shared[(threadIdx.x + 32)]*placeholder.shared[0]))\n        compute[6] = (compute[6] + (pad_temp.shared[(threadIdx.x + 48)]*placeholder.shared[0]))\n        compute[8] = (compute[8] + (pad_temp.shared[(threadIdx.x + 64)]*placeholder.shared[0]))\n        compute[10] = (compute[10] + (pad_temp.shared[(threadIdx.x + 80)]*placeholder.shared[0]))\n        compute[12] = (compute[12] + (pad_temp.shared[(threadIdx.x + 96)]*placeholder.shared[0]))\n        compute[1] = (compute[1] + (pad_temp.shared[threadIdx.x]*placeholder.shared[1]))\n        compute[3] = (compute[3] + (pad_temp.shared[(threadIdx.x + 16)]*placeholder.shared[1]))\n        compute[5] = (compute[5] + (pad_temp.shared[(threadIdx.x + 32)]*placeholder.shared[1]))\n        compute[7] = (compute[7] + (pad_temp.shared[(threadIdx.x + 48)]*placeholder.shared[1]))\n        compute[9] = (compute[9] + (pad_temp.shared[(threadIdx.x + 64)]*placeholder.shared[1]))\n        compute[11] = (compute[11] + (pad_temp.shared[(threadIdx.x + 80)]*placeholder.shared[1]))\n        compute[13] = (compute[13] + (pad_temp.shared[(threadIdx.x + 96)]*placeholder.shared[1]))\n        produce pad_temp.shared {\n          // attr [iter_var(threadIdx.z, , threadIdx.z)] thread_extent = 1\n          // attr [iter_var(threadIdx.y, , threadIdx.y)] thread_extent = 1\n          // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 16\n          pad_temp.shared[(threadIdx.x*7)] = tvm_if_then_else(((2 <= (blockIdx.y + ry.outer)) && ((blockIdx.y + ry.outer) < 226)), placeholder[((((((rc.outer*50176) + (blockIdx.y*224)) + (ry.outer*224)) + (blockIdx.x*112)) + (threadIdx.x*7)) - 448)], 0f)\n          pad_temp.shared[((threadIdx.x*7) + 1)] = tvm_if_then_else(((2 <= (blockIdx.y + ry.outer)) && ((blockIdx.y + ry.outer) < 226)), placeholder[((((((rc.outer*50176) + (blockIdx.y*224)) + (ry.outer*224)) + (blockIdx.x*112)) + (threadIdx.x*7)) - 447)], 0f)\n          pad_temp.shared[((threadIdx.x*7) + 2)] = tvm_if_then_else(((2 <= (blockIdx.y + ry.outer)) && ((blockIdx.y + ry.outer) < 226)), placeholder[((((((rc.outer*50176) + (blockIdx.y*224)) + (ry.outer*224)) + (blockIdx.x*112)) + (threadIdx.x*7)) - 446)], 0f)\n          pad_temp.shared[((threadIdx.x*7) + 3)] = tvm_if_then_else(((2 <= (blockIdx.y + ry.outer)) && ((blockIdx.y + ry.outer) < 226)), placeholder[((((((rc.outer*50176) + (blockIdx.y*224)) + (ry.outer*224)) + (blockIdx.x*112)) + (threadIdx.x*7)) - 445)], 0f)\n          pad_temp.shared[((threadIdx.x*7) + 4)] = tvm_if_then_else(((2 <= (blockIdx.y + ry.outer)) && ((blockIdx.y + ry.outer) < 226)), placeholder[((((((rc.outer*50176) + (blockIdx.y*224)) + (ry.outer*224)) + (blockIdx.x*112)) + (threadIdx.x*7)) - 444)], 0f)\n          pad_temp.shared[((threadIdx.x*7) + 5)] = tvm_if_then_else(((2 <= (blockIdx.y + ry.outer)) && ((blockIdx.y + ry.outer) < 226)), placeholder[((((((rc.outer*50176) + (blockIdx.y*224)) + (ry.outer*224)) + (blockIdx.x*112)) + (threadIdx.x*7)) - 443)], 0f)\n          pad_temp.shared[((threadIdx.x*7) + 6)] = tvm_if_then_else(((2 <= (blockIdx.y + ry.outer)) && ((blockIdx.y + ry.outer) < 226)), placeholder[((((((rc.outer*50176) + (blockIdx.y*224)) + (ry.outer*224)) + (blockIdx.x*112)) + (threadIdx.x*7)) - 442)], 0f)\n        }\n        produce placeholder.shared {\n          // attr [iter_var(threadIdx.z, , threadIdx.z)] thread_extent = 1\n          // attr [iter_var(threadIdx.y, , threadIdx.y)] thread_extent = 1\n          // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 16\n          if (likely((threadIdx.x < 2))) {\n            if (likely((threadIdx.x < 2))) {\n              if (likely((threadIdx.x < 2))) {\n                if (likely((threadIdx.x < 2))) {\n                  if (likely((threadIdx.x < 2))) {\n                    if (likely((threadIdx.x < 2))) {\n                      if (likely((((blockIdx.z*2) + threadIdx.x) < 10))) {\n                        placeholder.shared[threadIdx.x] = placeholder[(((((blockIdx.z*150) + (threadIdx.x*75)) + (rc.outer*25)) + (ry.outer*5)) + 2)]\n                      }\n                    }\n                  }\n                }\n              }\n            }\n          }\n        }\n        compute[0] = (compute[0] + (pad_temp.shared[threadIdx.x]*placeholder.shared[0]))\n        compute[2] = (compute[2] + (pad_temp.shared[(threadIdx.x + 16)]*placeholder.shared[0]))\n        compute[4] = (compute[4] + (pad_temp.shared[(threadIdx.x + 32)]*placeholder.shared[0]))\n        compute[6] = (compute[6] + (pad_temp.shared[(threadIdx.x + 48)]*placeholder.shared[0]))\n        compute[8] = (compute[8] + (pad_temp.shared[(threadIdx.x + 64)]*placeholder.shared[0]))\n        compute[10] = (compute[10] + (pad_temp.shared[(threadIdx.x + 80)]*placeholder.shared[0]))\n        compute[12] = (compute[12] + (pad_temp.shared[(threadIdx.x + 96)]*placeholder.shared[0]))\n        compute[1] = (compute[1] + (pad_temp.shared[threadIdx.x]*placeholder.shared[1]))\n        compute[3] = (compute[3] + (pad_temp.shared[(threadIdx.x + 16)]*placeholder.shared[1]))\n        compute[5] = (compute[5] + (pad_temp.shared[(threadIdx.x + 32)]*placeholder.shared[1]))\n        compute[7] = (compute[7] + (pad_temp.shared[(threadIdx.x + 48)]*placeholder.shared[1]))\n        compute[9] = (compute[9] + (pad_temp.shared[(threadIdx.x + 64)]*placeholder.shared[1]))\n        compute[11] = (compute[11] + (pad_temp.shared[(threadIdx.x + 80)]*placeholder.shared[1]))\n        compute[13] = (compute[13] + (pad_temp.shared[(threadIdx.x + 96)]*placeholder.shared[1]))\n        produce pad_temp.shared {\n          // attr [iter_var(threadIdx.z, , threadIdx.z)] thread_extent = 1\n          // attr [iter_var(threadIdx.y, , threadIdx.y)] thread_extent = 1\n          // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 16\n          pad_temp.shared[(threadIdx.x*7)] = tvm_if_then_else(((2 <= (blockIdx.y + ry.outer)) && ((blockIdx.y + ry.outer) < 226)), placeholder[((((((rc.outer*50176) + (blockIdx.y*224)) + (ry.outer*224)) + (blockIdx.x*112)) + (threadIdx.x*7)) - 447)], 0f)\n          pad_temp.shared[((threadIdx.x*7) + 1)] = tvm_if_then_else(((2 <= (blockIdx.y + ry.outer)) && ((blockIdx.y + ry.outer) < 226)), placeholder[((((((rc.outer*50176) + (blockIdx.y*224)) + (ry.outer*224)) + (blockIdx.x*112)) + (threadIdx.x*7)) - 446)], 0f)\n          pad_temp.shared[((threadIdx.x*7) + 2)] = tvm_if_then_else(((2 <= (blockIdx.y + ry.outer)) && ((blockIdx.y + ry.outer) < 226)), placeholder[((((((rc.outer*50176) + (blockIdx.y*224)) + (ry.outer*224)) + (blockIdx.x*112)) + (threadIdx.x*7)) - 445)], 0f)\n          pad_temp.shared[((threadIdx.x*7) + 3)] = tvm_if_then_else(((2 <= (blockIdx.y + ry.outer)) && ((blockIdx.y + ry.outer) < 226)), placeholder[((((((rc.outer*50176) + (blockIdx.y*224)) + (ry.outer*224)) + (blockIdx.x*112)) + (threadIdx.x*7)) - 444)], 0f)\n          pad_temp.shared[((threadIdx.x*7) + 4)] = tvm_if_then_else(((2 <= (blockIdx.y + ry.outer)) && ((blockIdx.y + ry.outer) < 226)), placeholder[((((((rc.outer*50176) + (blockIdx.y*224)) + (ry.outer*224)) + (blockIdx.x*112)) + (threadIdx.x*7)) - 443)], 0f)\n          pad_temp.shared[((threadIdx.x*7) + 5)] = tvm_if_then_else(((2 <= (blockIdx.y + ry.outer)) && ((blockIdx.y + ry.outer) < 226)), placeholder[((((((rc.outer*50176) + (blockIdx.y*224)) + (ry.outer*224)) + (blockIdx.x*112)) + (threadIdx.x*7)) - 442)], 0f)\n          pad_temp.shared[((threadIdx.x*7) + 6)] = tvm_if_then_else((((2 <= (blockIdx.y + ry.outer)) && ((blockIdx.y + ry.outer) < 226)) && (((blockIdx.x*112) + (threadIdx.x*7)) < 217)), placeholder[((((((rc.outer*50176) + (blockIdx.y*224)) + (ry.outer*224)) + (blockIdx.x*112)) + (threadIdx.x*7)) - 441)], 0f)\n        }\n        produce placeholder.shared {\n          // attr [iter_var(threadIdx.z, , threadIdx.z)] thread_extent = 1\n          // attr [iter_var(threadIdx.y, , threadIdx.y)] thread_extent = 1\n          // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 16\n          if (likely((threadIdx.x < 2))) {\n            if (likely((threadIdx.x < 2))) {\n              if (likely((threadIdx.x < 2))) {\n                if (likely((threadIdx.x < 2))) {\n                  if (likely((threadIdx.x < 2))) {\n                    if (likely((threadIdx.x < 2))) {\n                      if (likely((((blockIdx.z*2) + threadIdx.x) < 10))) {\n                        placeholder.shared[threadIdx.x] = placeholder[(((((blockIdx.z*150) + (threadIdx.x*75)) + (rc.outer*25)) + (ry.outer*5)) + 3)]\n                      }\n                    }\n                  }\n                }\n              }\n            }\n          }\n        }\n        compute[0] = (compute[0] + (pad_temp.shared[threadIdx.x]*placeholder.shared[0]))\n        compute[2] = (compute[2] + (pad_temp.shared[(threadIdx.x + 16)]*placeholder.shared[0]))\n        compute[4] = (compute[4] + (pad_temp.shared[(threadIdx.x + 32)]*placeholder.shared[0]))\n        compute[6] = (compute[6] + (pad_temp.shared[(threadIdx.x + 48)]*placeholder.shared[0]))\n        compute[8] = (compute[8] + (pad_temp.shared[(threadIdx.x + 64)]*placeholder.shared[0]))\n        compute[10] = (compute[10] + (pad_temp.shared[(threadIdx.x + 80)]*placeholder.shared[0]))\n        compute[12] = (compute[12] + (pad_temp.shared[(threadIdx.x + 96)]*placeholder.shared[0]))\n        compute[1] = (compute[1] + (pad_temp.shared[threadIdx.x]*placeholder.shared[1]))\n        compute[3] = (compute[3] + (pad_temp.shared[(threadIdx.x + 16)]*placeholder.shared[1]))\n        compute[5] = (compute[5] + (pad_temp.shared[(threadIdx.x + 32)]*placeholder.shared[1]))\n        compute[7] = (compute[7] + (pad_temp.shared[(threadIdx.x + 48)]*placeholder.shared[1]))\n        compute[9] = (compute[9] + (pad_temp.shared[(threadIdx.x + 64)]*placeholder.shared[1]))\n        compute[11] = (compute[11] + (pad_temp.shared[(threadIdx.x + 80)]*placeholder.shared[1]))\n        compute[13] = (compute[13] + (pad_temp.shared[(threadIdx.x + 96)]*placeholder.shared[1]))\n        produce pad_temp.shared {\n          // attr [iter_var(threadIdx.z, , threadIdx.z)] thread_extent = 1\n          // attr [iter_var(threadIdx.y, , threadIdx.y)] thread_extent = 1\n          // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 16\n          pad_temp.shared[(threadIdx.x*7)] = tvm_if_then_else(((2 <= (blockIdx.y + ry.outer)) && ((blockIdx.y + ry.outer) < 226)), placeholder[((((((rc.outer*50176) + (blockIdx.y*224)) + (ry.outer*224)) + (blockIdx.x*112)) + (threadIdx.x*7)) - 446)], 0f)\n          pad_temp.shared[((threadIdx.x*7) + 1)] = tvm_if_then_else(((2 <= (blockIdx.y + ry.outer)) && ((blockIdx.y + ry.outer) < 226)), placeholder[((((((rc.outer*50176) + (blockIdx.y*224)) + (ry.outer*224)) + (blockIdx.x*112)) + (threadIdx.x*7)) - 445)], 0f)\n          pad_temp.shared[((threadIdx.x*7) + 2)] = tvm_if_then_else(((2 <= (blockIdx.y + ry.outer)) && ((blockIdx.y + ry.outer) < 226)), placeholder[((((((rc.outer*50176) + (blockIdx.y*224)) + (ry.outer*224)) + (blockIdx.x*112)) + (threadIdx.x*7)) - 444)], 0f)\n          pad_temp.shared[((threadIdx.x*7) + 3)] = tvm_if_then_else(((2 <= (blockIdx.y + ry.outer)) && ((blockIdx.y + ry.outer) < 226)), placeholder[((((((rc.outer*50176) + (blockIdx.y*224)) + (ry.outer*224)) + (blockIdx.x*112)) + (threadIdx.x*7)) - 443)], 0f)\n          pad_temp.shared[((threadIdx.x*7) + 4)] = tvm_if_then_else(((2 <= (blockIdx.y + ry.outer)) && ((blockIdx.y + ry.outer) < 226)), placeholder[((((((rc.outer*50176) + (blockIdx.y*224)) + (ry.outer*224)) + (blockIdx.x*112)) + (threadIdx.x*7)) - 442)], 0f)\n          pad_temp.shared[((threadIdx.x*7) + 5)] = tvm_if_then_else((((2 <= (blockIdx.y + ry.outer)) && ((blockIdx.y + ry.outer) < 226)) && (((blockIdx.x*112) + (threadIdx.x*7)) < 217)), placeholder[((((((rc.outer*50176) + (blockIdx.y*224)) + (ry.outer*224)) + (blockIdx.x*112)) + (threadIdx.x*7)) - 441)], 0f)\n          pad_temp.shared[((threadIdx.x*7) + 6)] = tvm_if_then_else((((2 <= (blockIdx.y + ry.outer)) && ((blockIdx.y + ry.outer) < 226)) && (((blockIdx.x*112) + (threadIdx.x*7)) < 216)), placeholder[((((((rc.outer*50176) + (blockIdx.y*224)) + (ry.outer*224)) + (blockIdx.x*112)) + (threadIdx.x*7)) - 440)], 0f)\n        }\n        produce placeholder.shared {\n          // attr [iter_var(threadIdx.z, , threadIdx.z)] thread_extent = 1\n          // attr [iter_var(threadIdx.y, , threadIdx.y)] thread_extent = 1\n          // attr [iter_var(threadIdx.x, , threadIdx.x)] thread_extent = 16\n          if (likely((threadIdx.x < 2))) {\n            if (likely((threadIdx.x < 2))) {\n              if (likely((threadIdx.x < 2))) {\n                if (likely((threadIdx.x < 2))) {\n                  if (likely((threadIdx.x < 2))) {\n                    if (likely((threadIdx.x < 2))) {\n                      if (likely((((blockIdx.z*2) + threadIdx.x) < 10))) {\n                        placeholder.shared[threadIdx.x] = placeholder[(((((blockIdx.z*150) + (threadIdx.x*75)) + (rc.outer*25)) + (ry.outer*5)) + 4)]\n                      }\n                    }\n                  }\n                }\n              }\n            }\n          }\n        }\n        compute[0] = (compute[0] + (pad_temp.shared[threadIdx.x]*placeholder.shared[0]))\n        compute[2] = (compute[2] + (pad_temp.shared[(threadIdx.x + 16)]*placeholder.shared[0]))\n        compute[4] = (compute[4] + (pad_temp.shared[(threadIdx.x + 32)]*placeholder.shared[0]))\n        compute[6] = (compute[6] + (pad_temp.shared[(threadIdx.x + 48)]*placeholder.shared[0]))\n        compute[8] = (compute[8] + (pad_temp.shared[(threadIdx.x + 64)]*placeholder.shared[0]))\n        compute[10] = (compute[10] + (pad_temp.shared[(threadIdx.x + 80)]*placeholder.shared[0]))\n        compute[12] = (compute[12] + (pad_temp.shared[(threadIdx.x + 96)]*placeholder.shared[0]))\n        compute[1] = (compute[1] + (pad_temp.shared[threadIdx.x]*placeholder.shared[1]))\n        compute[3] = (compute[3] + (pad_temp.shared[(threadIdx.x + 16)]*placeholder.shared[1]))\n        compute[5] = (compute[5] + (pad_temp.shared[(threadIdx.x + 32)]*placeholder.shared[1]))\n        compute[7] = (compute[7] + (pad_temp.shared[(threadIdx.x + 48)]*placeholder.shared[1]))\n        compute[9] = (compute[9] + (pad_temp.shared[(threadIdx.x + 64)]*placeholder.shared[1]))\n        compute[11] = (compute[11] + (pad_temp.shared[(threadIdx.x + 80)]*placeholder.shared[1]))\n        compute[13] = (compute[13] + (pad_temp.shared[(threadIdx.x + 96)]*placeholder.shared[1]))\n      }\n    }\n  }\n  compute[((((blockIdx.z*100352) + (blockIdx.y*224)) + (blockIdx.x*112)) + threadIdx.x)] = max(compute[0], 0f)\n  compute[(((((blockIdx.z*100352) + (blockIdx.y*224)) + (blockIdx.x*112)) + threadIdx.x) + 16)] = max(compute[2], 0f)\n  compute[(((((blockIdx.z*100352) + (blockIdx.y*224)) + (blockIdx.x*112)) + threadIdx.x) + 32)] = max(compute[4], 0f)\n  compute[(((((blockIdx.z*100352) + (blockIdx.y*224)) + (blockIdx.x*112)) + threadIdx.x) + 48)] = max(compute[6], 0f)\n  compute[(((((blockIdx.z*100352) + (blockIdx.y*224)) + (blockIdx.x*112)) + threadIdx.x) + 64)] = max(compute[8], 0f)\n  compute[(((((blockIdx.z*100352) + (blockIdx.y*224)) + (blockIdx.x*112)) + threadIdx.x) + 80)] = max(compute[10], 0f)\n  compute[(((((blockIdx.z*100352) + (blockIdx.y*224)) + (blockIdx.x*112)) + threadIdx.x) + 96)] = max(compute[12], 0f)\n  compute[(((((blockIdx.z*100352) + (blockIdx.y*224)) + (blockIdx.x*112)) + threadIdx.x) + 50176)] = max(compute[1], 0f)\n  compute[(((((blockIdx.z*100352) + (blockIdx.y*224)) + (blockIdx.x*112)) + threadIdx.x) + 50192)] = max(compute[3], 0f)\n  compute[(((((blockIdx.z*100352) + (blockIdx.y*224)) + (blockIdx.x*112)) + threadIdx.x) + 50208)] = max(compute[5], 0f)\n  compute[(((((blockIdx.z*100352) + (blockIdx.y*224)) + (blockIdx.x*112)) + threadIdx.x) + 50224)] = max(compute[7], 0f)\n  compute[(((((blockIdx.z*100352) + (blockIdx.y*224)) + (blockIdx.x*112)) + threadIdx.x) + 50240)] = max(compute[9], 0f)\n  compute[(((((blockIdx.z*100352) + (blockIdx.y*224)) + (blockIdx.x*112)) + threadIdx.x) + 50256)] = max(compute[11], 0f)\n  compute[(((((blockIdx.z*100352) + (blockIdx.y*224)) + (blockIdx.x*112)) + threadIdx.x) + 50272)] = max(compute[13], 0f)\n}\n\n"
        }
      ],
      "source": [
        "data = te.placeholder((1, 3, 224, 224))\n",
        "kernel = te.placeholder((10, 3, 5, 5))\n",
        "\n",
        "with tvm.target.create(\"cuda\"):\n",
        "    conv = topi.cuda.conv2d_nchw(data, kernel, 1, 2, 1)\n",
        "    out = topi.nn.relu(conv)\n",
        "    sconv = topi.cuda.schedule_conv2d_nchw([out])\n",
        "    print(tvm.lower(sconv, [data, kernel], simple_mode=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Summary\n-------\nIn this tutorial, we have seen\n\n- How to use TOPI API for common operations with numpy-style operators.\n- How TOPI facilitates generic schedules and operator fusion for a context, to generate optimized kernel codes.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9-final"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}