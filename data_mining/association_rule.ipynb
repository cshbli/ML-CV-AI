{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Association Rules Mining\n",
    "\n",
    "Based on the transaction history, many patterns can be exploited to understand customer behaviors. One of the insights that can be achieved is the associations between items purchased. Using the data of all items bought, we can determine which items are usually purchased or purchased together, thereby defining and building up product association models. Conclusions must be tested for probability and reliability. For example, a person goes to a supermarket to buy bread. It is an 80% chance that he/she might purchase jam or ham to eat with bread with 90% confidence."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apriori Algorithm\n",
    "\n",
    "Apriori is an algorithm used to identify frequent item sets (in our case, item pairs). It does so using a \"bottom up\" approach, first identifying individual items that satisfy a minimum occurence threshold. It then extends the item set, adding one item at a time and checking if the resulting item set still satisfies the specified threshold. The algorithm stops when there are no more items to add that meet the minimum occurrence requirement. Here's an example of apriori in action, assuming a minimum occurence threshold of 3:\n",
    "\n",
    "```text\n",
    "order 1: apple, egg, milk  \n",
    "order 2: carrot, milk  \n",
    "order 3: apple, egg, carrot\n",
    "order 4: apple, egg\n",
    "order 5: apple, carrot\n",
    "\n",
    "\n",
    "Iteration 1:  Count the number of times each item occurs   \n",
    "item set      occurrence count    \n",
    "{apple}              4   \n",
    "{egg}                3   \n",
    "{milk}               2   \n",
    "{carrot}             2   \n",
    "\n",
    "{milk} and {carrot} are eliminated because they do not meet the minimum occurrence threshold.\n",
    "\n",
    "\n",
    "Iteration 2: Build item sets of size 2 using the remaining items from Iteration 1 \n",
    "             (ie: apple, egg)  \n",
    "item set           occurence count  \n",
    "{apple, egg}             3  \n",
    "\n",
    "Only {apple, egg} remains and the algorithm stops since there are no more items to add.\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Association Rules Mining\n",
    "\n",
    "Once the item sets have been generated using apriori, we can start mining association rules. Given that we are only looking at item sets of size 2, the association rules we will generate will be of the form {A} -> {B}. One common application of these rules is in the domain of recommender systems, where customers who purchased item A are recommended item B.\n",
    "\n",
    "Here are 3 key metrics to consider when evaluating association rules:\n",
    "\n",
    "1. support\n",
    "This is the percentage of orders that contains the item set. In the example above, there are 5 orders in total and {apple,egg} occurs in 3 of them, so:\n",
    "\n",
    "             support{apple,egg} = 3/5 or 60%\n",
    "\n",
    "The minimum support threshold required by apriori can be set based on knowledge of your domain. In this grocery dataset for example, since there could be thousands of distinct items and an order can contain only a small fraction of these items, setting the support threshold to 0.01% may be reasonable.\n",
    "\n",
    "2. confidence\n",
    "Given two items, A and B, confidence measures the percentage of times that item B is purchased, given that item A was purchased. This is expressed as:\n",
    "\n",
    "             confidence{A->B} = support{A,B} / support{A}   \n",
    "\n",
    "Confidence values range from 0 to 1, where 0 indicates that B is never purchased when A is purchased, and 1 indicates that B is always purchased whenever A is purchased. Note that the confidence measure is directional. This means that we can also compute the percentage of times that item A is purchased, given that item B was purchased:\n",
    "\n",
    "             confidence{B->A} = support{A,B} / support{B}    \n",
    "\n",
    "In our example, the percentage of times that egg is purchased, given that apple was purchased is:\n",
    "\n",
    "             confidence{apple->egg} = support{apple,egg} / support{apple}\n",
    "                                    = (3/5) / (4/5)\n",
    "                                    = 0.75 or 75%\n",
    "\n",
    "A confidence value of 0.75 implies that out of all orders that contain apple, 75% of them also contain egg. Now, we look at the confidence measure in the opposite direction (ie: egg->apple):\n",
    "\n",
    "             confidence{egg->apple} = support{apple,egg} / support{egg}\n",
    "                                    = (3/5) / (3/5)\n",
    "                                    = 1 or 100%  \n",
    "\n",
    "Here we see that all of the orders that contain egg also contain apple. But, does this mean that there is a relationship between these two items, or are they occurring together in the same orders simply by chance? To answer this question, we look at another measure which takes into account the popularity of both items.\n",
    "\n",
    "3. lift\n",
    "Given two items, A and B, lift indicates whether there is a relationship between A and B, or whether the two items are occuring together in the same orders simply by chance (ie: at random). Unlike the confidence metric whose value may vary depending on direction (eg: confidence{A->B} may be different from confidence{B->A}), lift has no direction. This means that the lift{A,B} is always equal to the lift{B,A}:\n",
    "\n",
    "             lift{A,B} = lift{B,A} = support{A,B} / (support{A} * support{B})   \n",
    "\n",
    "In our example, we compute lift as follows:\n",
    "\n",
    "  lift{apple,egg} = lift{egg,apple} = support{apple,egg} / (support{apple} * support{egg})\n",
    "                  = (3/5) / (4/5 * 3/5) \n",
    "                  = 1.25    \n",
    "\n",
    "One way to understand lift is to think of the denominator as the likelihood that A and B will appear in the same order if there was no relationship between them. In the example above, if apple occurred in 80% of the orders and egg occurred in 60% of the orders, then if there was no relationship between them, we would expect both of them to show up together in the same order 48% of the time (ie: 80% * 60%). The numerator, on the other hand, represents how often apple and egg actually appear together in the same order. In this example, that is 60% of the time. Taking the numerator and dividing it by the denominator, we get to how many more times apple and egg actually appear in the same order, compared to if there was no relationship between them (ie: that they are occurring together simply at random).\n",
    "\n",
    "In summary, lift can take on the following values:\n",
    "\n",
    " * lift = 1 implies no relationship between A and B. \n",
    "   (ie: A and B occur together only by chance)\n",
    "\n",
    " * lift > 1 implies that there is a positive relationship between A and B.\n",
    "   (ie:  A and B occur together more often than random)\n",
    "\n",
    " * lift < 1 implies that there is a negative relationship between A and B.\n",
    "   (ie:  A and B occur together less often than random)\n",
    "\n",
    "In our example, apple and egg occur together 1.25 times more than random, so we conclude that there exists a positive relationship between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from itertools import combinations, groupby\n",
    "from collections import Counter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "For this article, I will use a dataset from a bakery (License: CC0: Public Domain). This dataset includes 20507 entries, over 9000 transactions, and 5 columns. You can download the data from this [link](https://www.kaggle.com/datasets/mittalvasu95/the-bread-basket)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load order data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transaction</th>\n",
       "      <th>Item</th>\n",
       "      <th>date_time</th>\n",
       "      <th>period_day</th>\n",
       "      <th>weekday_weekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Bread</td>\n",
       "      <td>30-10-2016 09:58</td>\n",
       "      <td>morning</td>\n",
       "      <td>weekend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Scandinavian</td>\n",
       "      <td>30-10-2016 10:05</td>\n",
       "      <td>morning</td>\n",
       "      <td>weekend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Scandinavian</td>\n",
       "      <td>30-10-2016 10:05</td>\n",
       "      <td>morning</td>\n",
       "      <td>weekend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Hot chocolate</td>\n",
       "      <td>30-10-2016 10:07</td>\n",
       "      <td>morning</td>\n",
       "      <td>weekend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Jam</td>\n",
       "      <td>30-10-2016 10:07</td>\n",
       "      <td>morning</td>\n",
       "      <td>weekend</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Transaction           Item         date_time period_day weekday_weekend\n",
       "0            1          Bread  30-10-2016 09:58    morning         weekend\n",
       "1            2   Scandinavian  30-10-2016 10:05    morning         weekend\n",
       "2            2   Scandinavian  30-10-2016 10:05    morning         weekend\n",
       "3            3  Hot chocolate  30-10-2016 10:07    morning         weekend\n",
       "4            3            Jam  30-10-2016 10:07    morning         weekend"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders = pd.read_csv('./bread basket.csv')\n",
    "orders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transaction</th>\n",
       "      <th>Item</th>\n",
       "      <th>date_time</th>\n",
       "      <th>period_day</th>\n",
       "      <th>weekday_weekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20502</th>\n",
       "      <td>9682</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>09-04-2017 14:32</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>weekend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20503</th>\n",
       "      <td>9682</td>\n",
       "      <td>Tea</td>\n",
       "      <td>09-04-2017 14:32</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>weekend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20504</th>\n",
       "      <td>9683</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>09-04-2017 14:57</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>weekend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20505</th>\n",
       "      <td>9683</td>\n",
       "      <td>Pastry</td>\n",
       "      <td>09-04-2017 14:57</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>weekend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20506</th>\n",
       "      <td>9684</td>\n",
       "      <td>Smoothies</td>\n",
       "      <td>09-04-2017 15:04</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>weekend</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Transaction       Item         date_time period_day weekday_weekend\n",
       "20502         9682     Coffee  09-04-2017 14:32  afternoon         weekend\n",
       "20503         9682        Tea  09-04-2017 14:32  afternoon         weekend\n",
       "20504         9683     Coffee  09-04-2017 14:57  afternoon         weekend\n",
       "20505         9683     Pastry  09-04-2017 14:57  afternoon         weekend\n",
       "20506         9684  Smoothies  09-04-2017 15:04  afternoon         weekend"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders.tail()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform the dataset\n",
    "\n",
    "Because items in a transaction are split into different rows, I will group those items into a place. A list of lists of items is converted as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = []\n",
    "# Combine items in the same transaction into one place\n",
    "for i in orders.Transaction.unique():\n",
    "    list_trans = list(set(orders[orders.Transaction == i][\"Item\"]))\n",
    "    if len(list_trans) > 0:\n",
    "        transactions.append(list_trans)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Apriori module requires a data frame with values of 0 and 1 or True and False. Therefore, I will use One Hot Encode the data to meet the requirement of the Apriori module given by mlxtend library.\n",
    "\n",
    "You may need to install `mlxtend` library first by\n",
    "\n",
    "```bash\n",
    "pip install mlxtend\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlxtend\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import association_rules, apriori\n",
    "\n",
    "trans_encoding = TransactionEncoder()\n",
    "df2 = trans_encoding.fit(transactions).transform(transactions)\n",
    "df3 = pd.DataFrame(df2, columns=trans_encoding.columns_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can easily apply the apriori module from mlxtend library. The frequent sets are found with just one line of code. In this example, I will use the `min_support = 0.05` , which implies the minimum support required for an itemset to be chosen. Meanwhile,`use_colnames = True` keeps column names for itemsets to make them more understandable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_set = apriori(df3, min_support = 0.05, use_colnames = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     support         itemsets\n",
      "0   0.327205          (Bread)\n",
      "1   0.103856           (Cake)\n",
      "2   0.478394         (Coffee)\n",
      "3   0.054411        (Cookies)\n",
      "4   0.058320  (Hot chocolate)\n",
      "5   0.061807      (Medialuna)\n",
      "6   0.086107         (Pastry)\n",
      "7   0.071844       (Sandwich)\n",
      "8   0.142631            (Tea)\n",
      "9   0.090016  (Coffee, Bread)\n",
      "10  0.054728   (Coffee, Cake)\n"
     ]
    }
   ],
   "source": [
    "print(frequent_set)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these frequent sets, I continue to find the association rules which determine if A is bought, then B is also purchased. I set the metric = 'lift' with the minimum threshold = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rules = association_rules(frequent_set, metric = 'lift', min_threshold = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  antecedents consequents  antecedent support  consequent support   support  \\\n",
      "0    (Coffee)      (Cake)            0.478394            0.103856  0.054728   \n",
      "1      (Cake)    (Coffee)            0.103856            0.478394  0.054728   \n",
      "\n",
      "   confidence      lift  leverage  conviction  \n",
      "0    0.114399  1.101515  0.005044    1.011905  \n",
      "1    0.526958  1.101515  0.005044    1.102664  \n"
     ]
    }
   ],
   "source": [
    "print(rules)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the results consist of two association rules only. Cake and Coffee are bought more frequently than random with the lift = 1.1 and 53% confidence."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- [Simple Market Basket Analysis with Association Rules Mining](https://towardsdatascience.com/introduction-to-simple-association-rules-mining-for-market-basket-analysis-ef8f2d613d87)\n",
    "\n",
    "- [Association Rules Mining/Market Basket Analysis](https://www.kaggle.com/code/datatheque/association-rules-mining-market-basket-analysis/notebook)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch1.13.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "244b52c780d94b616429aadbde29e2a1db21faa7d2cf5e7aa305dc90879c3934"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
