{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardization and Scaling in Data Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization\n",
    "\n",
    "The basic scaling of the data is to do make it standard so that all the values will be in common range. In standardization, the mean and the variance of the data is zero and one respectively. It always tries to make a normal distribution of the data.\n",
    "\n",
    "The formula of the standardization is shown below:\n",
    "\n",
    "z = (column’s value — mean)/standard deviation\n",
    "\n",
    "<img src=\"pic/1_ooobvod71cCc4m4tma3rmA.webp\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "#creating a training data\n",
    "X_train = np.array([[ 4., -3.,  2.], \n",
    "                    [ 2.,  2.,  0.], \n",
    "                    [ 0.,  -6., 7.]])\n",
    "#fit the training data\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.        , -2.33333333,  3.        ])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.63299316, 3.29983165, 2.94392029])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.scale_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.22474487, -0.20203051, -0.33968311],\n",
       "       [ 0.        ,  1.31319831, -1.01904933],\n",
       "       [-1.22474487, -1.1111678 ,  1.35873244]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled = scaler.transform(X_train)\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled.std(axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MinMaxScaler\n",
    "\n",
    "The MinMaxScaler is another method to scale the data within a range of [0,1]. It keeps the data in original shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.375     , 0.28571429],\n",
       "       [0.5       , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "#creating a training data\n",
    "X_train = np.array([[ 4., -3.,  2.], \n",
    "                    [ 2.,  2.,  0.], \n",
    "                    [ 0.,  -6., 7.]])\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_train_minmax = min_max_scaler.fit_transform(X_train)\n",
    "X_train_minmax"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see after scaling with MinMaxScaler the data in the range of ‘0’ to ‘1’."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MaxAbsScaler\n",
    "\n",
    "This is another scaling method in which the data is in the range of [-1,1]. The benefit of this scaling is that it doesn’t shift or center the data and keeps the sparsity of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.5       ,  0.28571429],\n",
       "       [ 0.5       ,  0.33333333,  0.        ],\n",
       "       [ 0.        , -1.        ,  1.        ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "#creating a training data\n",
    "X_train = np.array([[ 4., -3.,  2.], \n",
    "                    [ 2.,  2.,  0.], \n",
    "                    [ 0.,  -6., 7.]])\n",
    "max_abs_scaler = preprocessing.MaxAbsScaler()\n",
    "X_train_maxabs = max_abs_scaler.fit_transform(X_train)\n",
    "X_train_maxabs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see after scaling with MaxAbsScaler the data in the range of ‘-1’ to ‘1’."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch1.13.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "244b52c780d94b616429aadbde29e2a1db21faa7d2cf5e7aa305dc90879c3934"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
