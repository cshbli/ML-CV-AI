{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF (Term Frequency, Inverse Document Frequency)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Terminology\n",
    "\n",
    "* t -- term (word)\n",
    "* d -- document (set of words)\n",
    "* N -- count of corpus\n",
    "* corpus -- the total document set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Term Frequency (TF)\n",
    "\n",
    "The number of times a term occurs in a document is called <b>term frequency</b>.\n",
    "\n",
    "The weight of a term that occurs in a document is simply proportional to the term frequency.\n",
    "\n",
    "```text\n",
    "tf(t, d) = count of t in d / number of words in d\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Document Frequency (DF)\n",
    "\n",
    "DF is the count of occurrences of term t in the document set N. In other words, DF is the number of documents in which the word is present. \n",
    "\n",
    "```text\n",
    "df(t) = occurrence of t in documents\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Inverse Document Frequency (IDF)\n",
    "\n",
    "IDF is the inverse of the document frequency which measures the informativeness of term t. When we calculate IDF, it will be very low for the most occurring words such as stop words (because stop words such as “is” is present in almost all of the documents, and N/df will give a very low value to that word). This finally gives what we want, a relative weightage.\n",
    "\n",
    "```text\n",
    "idf(t) = N / df\n",
    "```\n",
    "\n",
    "Now there are few other problems with the IDF , in case of a large corpus,say 100,000,000 , the IDF value explodes , to avoid the effect we take the log of idf.\n",
    "\n",
    "During the query time, when a word which is not in vocab occurs, the df will be 0. As we cannot divide by 0, we smoothen the value by adding 1 to the denominator.\n",
    "\n",
    "```text\n",
    "idf(t) = log(N / (df + 1))\n",
    "```\n",
    "\n",
    "tf-idf now is a the right measure to evaluate how important a word is to a document in a collection or corpus. There are many different variations of TF-IDF but for now let us concentrate on the this basic version.\n",
    "\n",
    "```text\n",
    "tf-idf(t, d) = tf(t, d) * log(N/(df + 1))\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'is', 'job', 'data', 'century', 'sexiest', 'key', 'the', 'for', 'Data', 'machine', 'learning', 'science', 'of', '21st'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "first_sentence = \"Data science is the sexiest job of the 21st century\"\n",
    "second_sentence = \"machine learning is the key for data science\"\n",
    "\n",
    "# split so each word have their own string\n",
    "# after split, it will become an array\n",
    "first_sentence = first_sentence.split(\" \")\n",
    "second_sentence = second_sentence.split(\" \")\n",
    "total = set(first_sentence).union(second_sentence)\n",
    "print(total)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets add a way to count the words using a dictionary key-value pairing for both sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordDictA = dict.fromkeys(total, 0)\n",
    "wordDictB = dict.fromkeys(total, 0)\n",
    "\n",
    "for word in first_sentence:\n",
    "    wordDictA[word] += 1\n",
    "\n",
    "for word in second_sentence:\n",
    "    wordDictB[word] += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we put them in a dataframe and then view the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is</th>\n",
       "      <th>job</th>\n",
       "      <th>data</th>\n",
       "      <th>century</th>\n",
       "      <th>sexiest</th>\n",
       "      <th>key</th>\n",
       "      <th>the</th>\n",
       "      <th>for</th>\n",
       "      <th>Data</th>\n",
       "      <th>machine</th>\n",
       "      <th>learning</th>\n",
       "      <th>science</th>\n",
       "      <th>of</th>\n",
       "      <th>21st</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is  job  data  century  sexiest  key  the  for  Data  machine  learning  \\\n",
       "0   1    1     0        1        1    0    2    0     1        0         0   \n",
       "1   1    0     1        0        0    1    1    1     0        1         1   \n",
       "\n",
       "   science  of  21st  \n",
       "0        1   1     1  \n",
       "1        1   0     0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([wordDictA, wordDictB])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's write the TF fuction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      is  job   data  century  sexiest    key    the    for  Data  machine  \\\n",
      "0  0.100  0.1  0.000      0.1      0.1  0.000  0.200  0.000   0.1    0.000   \n",
      "1  0.125  0.0  0.125      0.0      0.0  0.125  0.125  0.125   0.0    0.125   \n",
      "\n",
      "   learning  science   of  21st  \n",
      "0     0.000    0.100  0.1   0.1  \n",
      "1     0.125    0.125  0.0   0.0  \n"
     ]
    }
   ],
   "source": [
    "def computeTF(wordDict, doc):\n",
    "    tfDict = {}\n",
    "    corpusCount = len(doc)\n",
    "    for word, count in wordDict.items():\n",
    "        tfDict[word] = count / float(corpusCount)\n",
    "    return tfDict\n",
    "\n",
    "# running our sentence through the tf function:\n",
    "tfFirst = computeTF(wordDictA, first_sentence)\n",
    "tfSecond = computeTF(wordDictB, second_sentence)\n",
    "\n",
    "# Converting to data frame for visualization\n",
    "tf = pd.DataFrame([tfFirst, tfSecond])\n",
    "print(tf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should eliminate stop words because they are the most commonly occurring words which don’t give any additional value to the document vector. In-fact removing these will increase computation and space efficiency.\n",
    "\n",
    "`nltk` library has a method to download the stopwords, so instead of explicitly mentioning all the stopwords ourselves we can just use the nltk library and iterate over all the words and remove the stop words. There are many efficient ways to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['job', 'data', 'century', 'sexiest', 'key', 'Data', 'machine', 'learning', 'science', '21st']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/hongbing/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "filtered_sentence = [w for w in wordDictA if not w in stop_words]\n",
    "print(filtered_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeIDF(docList):\n",
    "    idfDict = {}\n",
    "    N = len(docList)\n",
    "    \n",
    "    idfDict = dict.fromkeys(docList[0].keys(), 0)\n",
    "    for word, val in idfDict.items():\n",
    "        idfDict[word] = math.log10(N / (float(val) + 1))\n",
    "        \n",
    "    return(idfDict)\n",
    "#inputing our sentences in the log file\n",
    "idfs = computeIDF([wordDictA, wordDictB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'is': 0.3010299956639812, 'job': 0.3010299956639812, 'data': 0.3010299956639812, 'century': 0.3010299956639812, 'sexiest': 0.3010299956639812, 'key': 0.3010299956639812, 'the': 0.3010299956639812, 'for': 0.3010299956639812, 'Data': 0.3010299956639812, 'machine': 0.3010299956639812, 'learning': 0.3010299956639812, 'science': 0.3010299956639812, 'of': 0.3010299956639812, '21st': 0.3010299956639812}\n"
     ]
    }
   ],
   "source": [
    "print(idfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         is       job      data   century   sexiest       key       the  \\\n",
      "0  0.030103  0.030103  0.000000  0.030103  0.030103  0.000000  0.060206   \n",
      "1  0.037629  0.000000  0.037629  0.000000  0.000000  0.037629  0.037629   \n",
      "\n",
      "        for      Data   machine  learning   science        of      21st  \n",
      "0  0.000000  0.030103  0.000000  0.000000  0.030103  0.030103  0.030103  \n",
      "1  0.037629  0.000000  0.037629  0.037629  0.037629  0.000000  0.000000  \n"
     ]
    }
   ],
   "source": [
    "def computeTFIDF(tfBow, idfs):\n",
    "    tfidf = {}\n",
    "    for word, val in tfBow.items():\n",
    "        tfidf[word] = val*idfs[word]\n",
    "    return(tfidf)\n",
    "#running our two sentences through the IDF:\n",
    "idfFirst = computeTFIDF(tfFirst, idfs)\n",
    "idfSecond = computeTFIDF(tfSecond, idfs)\n",
    "#putting it in a dataframe\n",
    "idf= pd.DataFrame([idfFirst, idfSecond])\n",
    "print(idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first step is to import the library\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#for the sentence, make sure all words are lowercase or you will run #into error. for simplicity, I just made the same sentence all #lowercase\n",
    "firstV= \"Data Science is the sexiest job of the 21st century\"\n",
    "secondV= \"machine learning is the key for data science\"\n",
    "\n",
    "#calling the TfidfVectorizer\n",
    "vectorize= TfidfVectorizer()\n",
    "#fitting the model and passing our sentences right away:\n",
    "response= vectorize.fit_transform([firstV, secondV])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t0.34211869506421816\n",
      "  (0, 0)\t0.34211869506421816\n",
      "  (0, 9)\t0.34211869506421816\n",
      "  (0, 5)\t0.34211869506421816\n",
      "  (0, 11)\t0.34211869506421816\n",
      "  (0, 12)\t0.48684053853849035\n",
      "  (0, 4)\t0.24342026926924518\n",
      "  (0, 10)\t0.24342026926924518\n",
      "  (0, 2)\t0.24342026926924518\n",
      "  (1, 3)\t0.40740123733358447\n",
      "  (1, 6)\t0.40740123733358447\n",
      "  (1, 7)\t0.40740123733358447\n",
      "  (1, 8)\t0.40740123733358447\n",
      "  (1, 12)\t0.28986933576883284\n",
      "  (1, 4)\t0.28986933576883284\n",
      "  (1, 10)\t0.28986933576883284\n",
      "  (1, 2)\t0.28986933576883284\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch1.13.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "244b52c780d94b616429aadbde29e2a1db21faa7d2cf5e7aa305dc90879c3934"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
