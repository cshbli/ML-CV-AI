{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pix2Pix Network, An Image-To-Image Translation Using Conditional GANsÂ (CGANs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the dataset from the following link \n",
    "http://efrosgans.eecs.berkeley.edu/pix2pix/datasets/cityscapes.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import keras.backend as K\n",
    "from copy import deepcopy\n",
    "from random import randint\n",
    "from keras import initializers\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import plot_model\n",
    "from keras.layers.core import Activation\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam, SGD, Nadam,Adamax\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers import  Flatten, Dropout, Lambda, Concatenate\n",
    "from keras.layers import Dense, Reshape, Input, BatchNormalization, Concatenate\n",
    "from keras.layers.convolutional import UpSampling2D, Convolution2D, MaxPooling2D,Deconvolution2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generator uses the U-NET architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(object):\n",
    "    def __init__(self, width = 28, height= 28, channels = 1):\n",
    "        \n",
    "        self.W = width\n",
    "        self.H = height\n",
    "        self.C = channels\n",
    "        self.SHAPE = (width,height,channels)\n",
    "\n",
    "        self.Generator = self.model()\n",
    "        self.OPTIMIZER = Adam(lr=2e-4, beta_1=0.5,decay=1e-5)\n",
    "        self.Generator.compile(loss='binary_crossentropy', optimizer=self.OPTIMIZER,metrics=['accuracy'])\n",
    "\n",
    "        self.save_model()\n",
    "        self.summary()\n",
    "\n",
    "    def model(self):\n",
    "        input_layer = Input(shape=self.SHAPE)\n",
    "        \n",
    "        down_1 = Convolution2D(64  , kernel_size=4, strides=2, padding='same',activation=LeakyReLU(alpha=0.2))(input_layer)\n",
    "\n",
    "        down_2 = Convolution2D(64*2, kernel_size=4, strides=2, padding='same',activation=LeakyReLU(alpha=0.2))(down_1)\n",
    "        norm_2 = BatchNormalization()(down_2)\n",
    "\n",
    "        down_3 = Convolution2D(64*4, kernel_size=4, strides=2, padding='same',activation=LeakyReLU(alpha=0.2))(norm_2)\n",
    "        norm_3 = BatchNormalization()(down_3)\n",
    "\n",
    "        down_4 = Convolution2D(64*8, kernel_size=4, strides=2, padding='same',activation=LeakyReLU(alpha=0.2))(norm_3)\n",
    "        norm_4 = BatchNormalization()(down_4)\n",
    "\n",
    "        down_5 = Convolution2D(64*8, kernel_size=4, strides=2, padding='same',activation=LeakyReLU(alpha=0.2))(norm_4)\n",
    "        norm_5 = BatchNormalization()(down_5)\n",
    "\n",
    "        down_6 = Convolution2D(64*8, kernel_size=4, strides=2, padding='same',activation=LeakyReLU(alpha=0.2))(norm_5)\n",
    "        norm_6 = BatchNormalization()(down_6)\n",
    "\n",
    "        down_7 = Convolution2D(64*8, kernel_size=4, strides=2, padding='same',activation=LeakyReLU(alpha=0.2))(norm_6)\n",
    "        norm_7 = BatchNormalization()(down_7)\n",
    "\n",
    "\n",
    "        upsample_1 = UpSampling2D(size=2)(norm_7)\n",
    "        up_conv_1 = Convolution2D(64*8, kernel_size=4, strides=1, padding='same',activation='relu')(upsample_1)\n",
    "        norm_up_1 = BatchNormalization(momentum=0.8)(up_conv_1)\n",
    "        add_skip_1 = Concatenate()([norm_up_1,norm_6])\n",
    "\n",
    "\n",
    "        upsample_2 = UpSampling2D(size=2)(add_skip_1)\n",
    "        up_conv_2 = Convolution2D(64*8, kernel_size=4, strides=1, padding='same',activation='relu')(upsample_2)\n",
    "        norm_up_2 = BatchNormalization(momentum=0.8)(up_conv_2)\n",
    "        add_skip_2 = Concatenate()([norm_up_2,norm_5])\n",
    "\n",
    "        upsample_3 = UpSampling2D(size=2)(add_skip_2)\n",
    "        up_conv_3 = Convolution2D(64*8, kernel_size=4, strides=1, padding='same',activation='relu')(upsample_3)\n",
    "        norm_up_3 = BatchNormalization(momentum=0.8)(up_conv_3)\n",
    "        add_skip_3 = Concatenate()([norm_up_3,norm_4])\n",
    "\n",
    "\n",
    "        upsample_4 = UpSampling2D(size=2)(add_skip_3)\n",
    "        up_conv_4 = Convolution2D(64*4, kernel_size=4, strides=1, padding='same',activation='relu')(upsample_4)\n",
    "        norm_up_4 = BatchNormalization(momentum=0.8)(up_conv_4)\n",
    "        add_skip_4 = Concatenate()([norm_up_4,norm_3])\n",
    "\n",
    "        upsample_5 = UpSampling2D(size=2)(add_skip_4)\n",
    "        up_conv_5 = Convolution2D(64*2, kernel_size=4, strides=1, padding='same',activation='relu')(upsample_5)\n",
    "        norm_up_5 = BatchNormalization(momentum=0.8)(up_conv_5)\n",
    "        add_skip_5 = Concatenate()([norm_up_5,norm_2])\n",
    "\n",
    "        upsample_6 = UpSampling2D(size=2)(add_skip_5)\n",
    "        up_conv_6 = Convolution2D(64, kernel_size=4, strides=1, padding='same',activation='relu')(upsample_6)\n",
    "        norm_up_6 = BatchNormalization(momentum=0.8)(up_conv_6)\n",
    "        add_skip_6 = Concatenate()([norm_up_6,down_1])\n",
    "\n",
    "        last_upsample = UpSampling2D(size=2)(add_skip_6)\n",
    "        output_layer = Convolution2D(self.C, kernel_size=4, strides=1, padding='same',activation='tanh')(last_upsample)\n",
    "        \n",
    "        return Model(input_layer,output_layer)\n",
    "\n",
    "    def summary(self):\n",
    "        return self.Generator.summary()\n",
    "\n",
    "    def save_model(self):\n",
    "        plot_model(self.Generator, to_file='./data/out/Generator_Model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discriminator network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(object):\n",
    "    def __init__(self, width = 28, height= 28, channels = 1, starting_filters=64):\n",
    "        self.W = width\n",
    "        self.H = height\n",
    "        self.C = channels\n",
    "        self.CAPACITY = width*height*channels\n",
    "        self.SHAPE = (width,height,channels)\n",
    "        self.FS = starting_filters #FilterStart\n",
    "        \n",
    "        self.Discriminator = self.model()\n",
    "        self.OPTIMIZER = Adam(lr=2e-4, beta_1=0.5,decay=1e-5)\n",
    "        self.Discriminator.compile(loss='mse', optimizer=self.OPTIMIZER, metrics=['accuracy'] )\n",
    "\n",
    "        self.save_model()\n",
    "        self.summary()\n",
    "\n",
    "    def model(self):\n",
    "\n",
    "\n",
    "        input_A = Input(shape=self.SHAPE)\n",
    "        input_B = Input(shape=self.SHAPE)\n",
    "        input_layer = Concatenate(axis=-1)([input_A, input_B])\n",
    "\n",
    "        up_layer_1 = Convolution2D(self.FS, kernel_size=4, strides=2, padding='same',activation=LeakyReLU(alpha=0.2))(input_layer)\n",
    "\n",
    "        up_layer_2 = Convolution2D(self.FS*2, kernel_size=4, strides=2, padding='same',activation=LeakyReLU(alpha=0.2))(up_layer_1)\n",
    "        leaky_layer_2 =  BatchNormalization(momentum=0.8)(up_layer_2)\n",
    "\n",
    "        up_layer_3 = Convolution2D(self.FS*4, kernel_size=4, strides=2, padding='same',activation=LeakyReLU(alpha=0.2))(leaky_layer_2)\n",
    "        leaky_layer_3 =  BatchNormalization(momentum=0.8)(up_layer_3)\n",
    "\n",
    "        up_layer_4 = Convolution2D(self.FS*8, kernel_size=4, strides=2, padding='same',activation=LeakyReLU(alpha=0.2))(leaky_layer_3)\n",
    "        leaky_layer_4 = BatchNormalization(momentum=0.8)(up_layer_4)\n",
    "\n",
    "        output_layer = Convolution2D(1, kernel_size=4, strides=1, padding='same')(leaky_layer_4)\n",
    "        \n",
    "        return Model([input_A, input_B],output_layer)\n",
    "\n",
    "    def summary(self):\n",
    "        return self.Discriminator.summary()\n",
    "\n",
    "    def save_model(self):\n",
    "        plot_model(self.Discriminator, to_file='./data/out/Discriminator_Model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAN Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(object):\n",
    "    def __init__(self, model_inputs=[],model_outputs=[]):\n",
    "        self.OPTIMIZER = SGD(lr=2e-4,nesterov=True)\n",
    "\n",
    "        self.inputs = model_inputs\n",
    "        self.outputs = model_outputs\n",
    "        self.gan_model = Model(inputs = self.inputs, outputs = self.outputs)\n",
    "        self.OPTIMIZER = Adam(lr=2e-4, beta_1=0.5)\n",
    "        self.gan_model.compile(loss=['mse', 'mae'],\n",
    "                            loss_weights=[  1, 100],\n",
    "                            optimizer=self.OPTIMIZER)\n",
    "        self.save_model()\n",
    "        self.summary()\n",
    "\n",
    "    def model(self):\n",
    "        model = Model()\n",
    "        return model\n",
    "\n",
    "    def summary(self):\n",
    "        return self.gan_model.summary()\n",
    "\n",
    "    def save_model(self):\n",
    "        plot_model(self.gan_model, to_file='./data/out/GAN_Model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trainer class for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, height = 256, width = 256, channels=3, epochs = 50000, batch = 1, checkpoint = 50, train_data_path = '',test_data_path=''):\n",
    "        self.EPOCHS = epochs\n",
    "        self.BATCH = batch\n",
    "        self.H = height\n",
    "        self.W = width\n",
    "        self.C = channels\n",
    "        self.CHECKPOINT = checkpoint\n",
    "\n",
    "        self.X_train_B, self.X_train_A = self.load_data(train_data_path)\n",
    "        self.X_test_B, self.X_test_A  = self.load_data(test_data_path)\n",
    "\n",
    "\n",
    "        self.generator = Generator(height=self.H, width=self.W, channels=self.C)\n",
    "\n",
    "        self.orig_A = Input(shape=(self.W, self.H, self.C))\n",
    "        self.orig_B = Input(shape=(self.W, self.H, self.C))\n",
    "\n",
    "        self.fake_A = self.generator.Generator(self.orig_B)\n",
    "\n",
    "        self.discriminator = Discriminator(height=self.H, width=self.W, channels=self.C)\n",
    "        self.discriminator.trainable = False\n",
    "        self.valid = self.discriminator.Discriminator([self.fake_A,self.orig_B])\n",
    "\n",
    "        model_inputs  = [self.orig_A,self.orig_B]\n",
    "        model_outputs = [self.valid, self.fake_A]\n",
    "        self.gan = GAN(model_inputs=model_inputs,model_outputs=model_outputs)\n",
    "        \n",
    "        \n",
    "\n",
    "    def load_data(self,data_path):\n",
    "        listOFFiles = self.grabListOfFiles(data_path,extension=\"jpg\")\n",
    "        imgs_temp = np.array(self.grabArrayOfImages(listOFFiles))\n",
    "        imgs_A = []\n",
    "        imgs_B = []\n",
    "        for img in imgs_temp:\n",
    "            imgs_A.append(img[:,:self.H])\n",
    "            imgs_B.append(img[:,self.H:])\n",
    "\n",
    "        imgs_A_out = self.norm_and_expand(np.array(imgs_A))\n",
    "        imgs_B_out = self.norm_and_expand(np.array(imgs_B))\n",
    "\n",
    "        return imgs_A_out, imgs_B_out\n",
    "\n",
    "    def norm_and_expand(self,arr):\n",
    "        arr = (arr.astype(np.float32) - 127.5)/127.5\n",
    "        normed = np.expand_dims(arr, axis=3)\n",
    "        return normed\n",
    "\n",
    "    def grabListOfFiles(self,startingDirectory,extension=\".webp\"):\n",
    "        listOfFiles = []\n",
    "        for file in os.listdir(startingDirectory):\n",
    "            if file.endswith(extension):\n",
    "                listOfFiles.append(os.path.join(startingDirectory, file))\n",
    "        return listOfFiles\n",
    "\n",
    "    def grabArrayOfImages(self,listOfFiles,gray=False):\n",
    "        imageArr = []\n",
    "        for f in listOfFiles:\n",
    "            if gray:\n",
    "                im = Image.open(f).convert(\"L\")\n",
    "            else:\n",
    "                im = Image.open(f).convert(\"RGB\")\n",
    "            imData = np.asarray(im)\n",
    "            imageArr.append(imData)\n",
    "        return imageArr\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        for e in range(self.EPOCHS):\n",
    "            b = 0\n",
    "            X_train_A_temp = deepcopy(self.X_train_A)\n",
    "            X_train_B_temp = deepcopy(self.X_train_B)\n",
    "\n",
    "            number_of_batches = len(self.X_train_A)\n",
    "        \n",
    "            for b in range(number_of_batches):\n",
    "                # Train Discriminator\n",
    "                # Grab Real Images for this training batch\n",
    "                starting_ind = randint(0, (len(X_train_A_temp)-1))\n",
    "                real_images_raw_A = X_train_A_temp[ starting_ind : (starting_ind + 1) ]\n",
    "                real_images_raw_B = X_train_B_temp[ starting_ind : (starting_ind + 1) ]\n",
    "\n",
    "                # Delete the images used until we have none left\n",
    "                X_train_A_temp = np.delete(X_train_A_temp,range(starting_ind,(starting_ind + 1)),0)\n",
    "                X_train_B_temp = np.delete(X_train_B_temp,range(starting_ind,(starting_ind + 1)),0)\n",
    "\n",
    "                batch_A = real_images_raw_A.reshape( 1, self.W, self.H, self.C )\n",
    "                batch_B = real_images_raw_B.reshape( 1, self.W, self.H, self.C )\n",
    "\n",
    "                # PatchGAN\n",
    "                y_valid = np.ones((1,)+(int(self.W / 2**4), int(self.W / 2**4), 1))\n",
    "                y_fake = np.zeros((1,)+(int(self.W / 2**4), int(self.W / 2**4), 1))\n",
    "\n",
    "                fake_A = self.generator.Generator.predict(batch_B)\n",
    "\n",
    "                # Now, train the discriminator with this batch of reals\n",
    "                discriminator_loss_real = self.discriminator.Discriminator.train_on_batch([batch_A,batch_B],y_valid)[0]\n",
    "                discriminator_loss_fake = self.discriminator.Discriminator.train_on_batch([fake_A,batch_B],y_fake)[0]\n",
    "                full_loss = 0.5 * np.add(discriminator_loss_real, discriminator_loss_fake)\n",
    "\n",
    "                generator_loss = self.gan.gan_model.train_on_batch([batch_A, batch_B],[y_valid,batch_A])    \n",
    "\n",
    "                print ('Batch: '+str(int(b))+', [Full Discriminator :: Loss: '+str(full_loss)+'], [ Generator :: Loss: '+str(generator_loss)+']')\n",
    "                if b % self.CHECKPOINT == 0 :\n",
    "                    label = str(e)+'_'+str(b)\n",
    "                    self.plot_checkpoint(label)\n",
    "\n",
    "            print ('Epoch: '+str(int(e))+', [Full Discriminator :: Loss:'+str(full_loss)+'], [ Generator :: Loss: '+str(generator_loss)+']')\n",
    "                        \n",
    "        return\n",
    "\n",
    "    def plot_checkpoint(self,b):\n",
    "        orig_filename = \"./data/out/batch_check_\"+str(b)+\"_original.png\"\n",
    "\n",
    "        r, c = 3, 3\n",
    "        random_inds = random.sample(range(len(self.X_test_A)),3)\n",
    "        imgs_A = self.X_test_A[random_inds].reshape(3, self.W, self.H, self.C )\n",
    "        imgs_B = self.X_test_B[random_inds].reshape( 3, self.W, self.H, self.C )\n",
    "        fake_A = self.generator.Generator.predict(imgs_B)\n",
    "\n",
    "        gen_imgs = np.concatenate([imgs_B, fake_A, imgs_A])\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        titles = ['Style', 'Generated', 'Original']\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt])\n",
    "                axs[i, j].set_title(titles[i])\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(\"./data/out/batch_check_\"+str(b)+\".png\")\n",
    "        plt.close('all')\n",
    "\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#discriminator = Discriminator(256, 256, 3)\n",
    "#generator = Generator(256, 256, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create instance of Trainer, with EPOCHS value 1 and BATCH of 1\n",
    "\n",
    "Please create one sub-dir \"./data/out\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"model_3\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_3 (InputLayer)            (None, 256, 256, 3)  0                                            \n__________________________________________________________________________________________________\nconv2d_29 (Conv2D)              (None, 128, 128, 64) 3136        input_3[0][0]                    \n__________________________________________________________________________________________________\nconv2d_30 (Conv2D)              (None, 64, 64, 128)  131200      conv2d_29[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_25 (BatchNo (None, 64, 64, 128)  512         conv2d_30[0][0]                  \n__________________________________________________________________________________________________\nconv2d_31 (Conv2D)              (None, 32, 32, 256)  524544      batch_normalization_25[0][0]     \n__________________________________________________________________________________________________\nbatch_normalization_26 (BatchNo (None, 32, 32, 256)  1024        conv2d_31[0][0]                  \n__________________________________________________________________________________________________\nconv2d_32 (Conv2D)              (None, 16, 16, 512)  2097664     batch_normalization_26[0][0]     \n__________________________________________________________________________________________________\nbatch_normalization_27 (BatchNo (None, 16, 16, 512)  2048        conv2d_32[0][0]                  \n__________________________________________________________________________________________________\nconv2d_33 (Conv2D)              (None, 8, 8, 512)    4194816     batch_normalization_27[0][0]     \n__________________________________________________________________________________________________\nbatch_normalization_28 (BatchNo (None, 8, 8, 512)    2048        conv2d_33[0][0]                  \n__________________________________________________________________________________________________\nconv2d_34 (Conv2D)              (None, 4, 4, 512)    4194816     batch_normalization_28[0][0]     \n__________________________________________________________________________________________________\nbatch_normalization_29 (BatchNo (None, 4, 4, 512)    2048        conv2d_34[0][0]                  \n__________________________________________________________________________________________________\nconv2d_35 (Conv2D)              (None, 2, 2, 512)    4194816     batch_normalization_29[0][0]     \n__________________________________________________________________________________________________\nbatch_normalization_30 (BatchNo (None, 2, 2, 512)    2048        conv2d_35[0][0]                  \n__________________________________________________________________________________________________\nup_sampling2d_15 (UpSampling2D) (None, 4, 4, 512)    0           batch_normalization_30[0][0]     \n__________________________________________________________________________________________________\nconv2d_36 (Conv2D)              (None, 4, 4, 512)    4194816     up_sampling2d_15[0][0]           \n__________________________________________________________________________________________________\nbatch_normalization_31 (BatchNo (None, 4, 4, 512)    2048        conv2d_36[0][0]                  \n__________________________________________________________________________________________________\nconcatenate_13 (Concatenate)    (None, 4, 4, 1024)   0           batch_normalization_31[0][0]     \n                                                                 batch_normalization_29[0][0]     \n__________________________________________________________________________________________________\nup_sampling2d_16 (UpSampling2D) (None, 8, 8, 1024)   0           concatenate_13[0][0]             \n__________________________________________________________________________________________________\nconv2d_37 (Conv2D)              (None, 8, 8, 512)    8389120     up_sampling2d_16[0][0]           \n__________________________________________________________________________________________________\nbatch_normalization_32 (BatchNo (None, 8, 8, 512)    2048        conv2d_37[0][0]                  \n__________________________________________________________________________________________________\nconcatenate_14 (Concatenate)    (None, 8, 8, 1024)   0           batch_normalization_32[0][0]     \n                                                                 batch_normalization_28[0][0]     \n__________________________________________________________________________________________________\nup_sampling2d_17 (UpSampling2D) (None, 16, 16, 1024) 0           concatenate_14[0][0]             \n__________________________________________________________________________________________________\nconv2d_38 (Conv2D)              (None, 16, 16, 512)  8389120     up_sampling2d_17[0][0]           \n__________________________________________________________________________________________________\nbatch_normalization_33 (BatchNo (None, 16, 16, 512)  2048        conv2d_38[0][0]                  \n__________________________________________________________________________________________________\nconcatenate_15 (Concatenate)    (None, 16, 16, 1024) 0           batch_normalization_33[0][0]     \n                                                                 batch_normalization_27[0][0]     \n__________________________________________________________________________________________________\nup_sampling2d_18 (UpSampling2D) (None, 32, 32, 1024) 0           concatenate_15[0][0]             \n__________________________________________________________________________________________________\nconv2d_39 (Conv2D)              (None, 32, 32, 256)  4194560     up_sampling2d_18[0][0]           \n__________________________________________________________________________________________________\nbatch_normalization_34 (BatchNo (None, 32, 32, 256)  1024        conv2d_39[0][0]                  \n__________________________________________________________________________________________________\nconcatenate_16 (Concatenate)    (None, 32, 32, 512)  0           batch_normalization_34[0][0]     \n                                                                 batch_normalization_26[0][0]     \n__________________________________________________________________________________________________\nup_sampling2d_19 (UpSampling2D) (None, 64, 64, 512)  0           concatenate_16[0][0]             \n__________________________________________________________________________________________________\nconv2d_40 (Conv2D)              (None, 64, 64, 128)  1048704     up_sampling2d_19[0][0]           \n__________________________________________________________________________________________________\nbatch_normalization_35 (BatchNo (None, 64, 64, 128)  512         conv2d_40[0][0]                  \n__________________________________________________________________________________________________\nconcatenate_17 (Concatenate)    (None, 64, 64, 256)  0           batch_normalization_35[0][0]     \n                                                                 batch_normalization_25[0][0]     \n__________________________________________________________________________________________________\nup_sampling2d_20 (UpSampling2D) (None, 128, 128, 256 0           concatenate_17[0][0]             \n__________________________________________________________________________________________________\nconv2d_41 (Conv2D)              (None, 128, 128, 64) 262208      up_sampling2d_20[0][0]           \n__________________________________________________________________________________________________\nbatch_normalization_36 (BatchNo (None, 128, 128, 64) 256         conv2d_41[0][0]                  \n__________________________________________________________________________________________________\nconcatenate_18 (Concatenate)    (None, 128, 128, 128 0           batch_normalization_36[0][0]     \n                                                                 conv2d_29[0][0]                  \n__________________________________________________________________________________________________\nup_sampling2d_21 (UpSampling2D) (None, 256, 256, 128 0           concatenate_18[0][0]             \n__________________________________________________________________________________________________\nconv2d_42 (Conv2D)              (None, 256, 256, 3)  6147        up_sampling2d_21[0][0]           \n==================================================================================================\nTotal params: 41,843,331\nTrainable params: 41,834,499\nNon-trainable params: 8,832\n__________________________________________________________________________________________________\nModel: \"model_4\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_6 (InputLayer)            (None, 256, 256, 3)  0                                            \n__________________________________________________________________________________________________\ninput_7 (InputLayer)            (None, 256, 256, 3)  0                                            \n__________________________________________________________________________________________________\nconcatenate_19 (Concatenate)    (None, 256, 256, 6)  0           input_6[0][0]                    \n                                                                 input_7[0][0]                    \n__________________________________________________________________________________________________\nconv2d_43 (Conv2D)              (None, 128, 128, 64) 6208        concatenate_19[0][0]             \n__________________________________________________________________________________________________\nconv2d_44 (Conv2D)              (None, 64, 64, 128)  131200      conv2d_43[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_37 (BatchNo (None, 64, 64, 128)  512         conv2d_44[0][0]                  \n__________________________________________________________________________________________________\nconv2d_45 (Conv2D)              (None, 32, 32, 256)  524544      batch_normalization_37[0][0]     \n__________________________________________________________________________________________________\nbatch_normalization_38 (BatchNo (None, 32, 32, 256)  1024        conv2d_45[0][0]                  \n__________________________________________________________________________________________________\nconv2d_46 (Conv2D)              (None, 16, 16, 512)  2097664     batch_normalization_38[0][0]     \n__________________________________________________________________________________________________\nbatch_normalization_39 (BatchNo (None, 16, 16, 512)  2048        conv2d_46[0][0]                  \n__________________________________________________________________________________________________\nconv2d_47 (Conv2D)              (None, 16, 16, 1)    8193        batch_normalization_39[0][0]     \n==================================================================================================\nTotal params: 2,771,393\nTrainable params: 2,769,601\nNon-trainable params: 1,792\n__________________________________________________________________________________________________\nModel: \"model_5\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_5 (InputLayer)            (None, 256, 256, 3)  0                                            \n__________________________________________________________________________________________________\nmodel_3 (Model)                 (None, 256, 256, 3)  41843331    input_5[0][0]                    \n__________________________________________________________________________________________________\nmodel_4 (Model)                 (None, 16, 16, 1)    2771393     model_3[1][0]                    \n                                                                 input_5[0][0]                    \n==================================================================================================\nTotal params: 44,614,724\nTrainable params: 44,604,100\nNon-trainable params: 10,624\n__________________________________________________________________________________________________\n"
    }
   ],
   "source": [
    "HEIGHT  = 256\n",
    "WIDTH   = 256\n",
    "CHANNELS = 3\n",
    "#EPOCHS = 5\n",
    "EPOCHS = 1\n",
    "BATCH = 1\n",
    "CHECKPOINT = 100\n",
    "TRAIN_PATH = \"./data/cityscapes/train/\"\n",
    "TEST_PATH = \"./data/cityscapes/val/\"\n",
    "\n",
    "trainer = Trainer(height=HEIGHT,width=WIDTH, channels=CHANNELS,epochs =EPOCHS,\\\n",
    "                 batch=BATCH,\\\n",
    "                 checkpoint=CHECKPOINT,\\\n",
    "                 train_data_path=TRAIN_PATH,\\\n",
    "                 test_data_path=TEST_PATH)\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "869171143], [ Generator :: Loss: [11.590365, 0.33055636, 0.11259809]]\nBatch: 2812, [Full Discriminator :: Loss: 0.03965310379862785], [ Generator :: Loss: [16.495077, 0.7892751, 0.15705803]]\nBatch: 2813, [Full Discriminator :: Loss: 0.10953105986118317], [ Generator :: Loss: [15.221852, 0.06703171, 0.1515482]]\nBatch: 2814, [Full Discriminator :: Loss: 0.11493577808141708], [ Generator :: Loss: [13.0082, 0.11810427, 0.12890096]]\nBatch: 2815, [Full Discriminator :: Loss: 0.050147704780101776], [ Generator :: Loss: [15.0349, 0.2057295, 0.1482917]]\nBatch: 2816, [Full Discriminator :: Loss: 0.15607288479804993], [ Generator :: Loss: [14.233681, 0.11194132, 0.1412174]]\nBatch: 2817, [Full Discriminator :: Loss: 0.17060954868793488], [ Generator :: Loss: [16.78407, 0.19171524, 0.16592354]]\nBatch: 2818, [Full Discriminator :: Loss: 0.0814598873257637], [ Generator :: Loss: [14.515349, 0.07273714, 0.14442612]]\nBatch: 2819, [Full Discriminator :: Loss: 0.06290876120328903], [ Generator :: Loss: [14.648216, 0.048261385, 0.14599955]]\nBatch: 2820, [Full Discriminator :: Loss: 0.03188972547650337], [ Generator :: Loss: [13.575372, 0.079672396, 0.13495699]]\nBatch: 2821, [Full Discriminator :: Loss: 0.3395429849624634], [ Generator :: Loss: [13.148142, 0.17726201, 0.1297088]]\nBatch: 2822, [Full Discriminator :: Loss: 0.07330675423145294], [ Generator :: Loss: [15.854521, 0.1427729, 0.15711749]]\nBatch: 2823, [Full Discriminator :: Loss: 0.057230137288570404], [ Generator :: Loss: [16.271982, 0.16376738, 0.16108215]]\nBatch: 2824, [Full Discriminator :: Loss: 0.03627411276102066], [ Generator :: Loss: [17.922777, 0.070698716, 0.1785208]]\nBatch: 2825, [Full Discriminator :: Loss: 0.0406673401594162], [ Generator :: Loss: [14.147798, 0.05837725, 0.1408942]]\nBatch: 2826, [Full Discriminator :: Loss: 0.05842594429850578], [ Generator :: Loss: [19.929155, 0.06809942, 0.19861056]]\nBatch: 2827, [Full Discriminator :: Loss: 0.04900835081934929], [ Generator :: Loss: [15.825428, 0.13580847, 0.1568962]]\nBatch: 2828, [Full Discriminator :: Loss: 0.08701297640800476], [ Generator :: Loss: [15.6095085, 0.07445318, 0.15535055]]\nBatch: 2829, [Full Discriminator :: Loss: 0.04494065046310425], [ Generator :: Loss: [25.795898, 0.05197285, 0.25743926]]\nBatch: 2830, [Full Discriminator :: Loss: 0.09275965392589569], [ Generator :: Loss: [12.295514, 0.035477262, 0.12260036]]\nBatch: 2831, [Full Discriminator :: Loss: 0.045079365372657776], [ Generator :: Loss: [21.114832, 0.23842116, 0.20876412]]\nBatch: 2832, [Full Discriminator :: Loss: 0.43177756667137146], [ Generator :: Loss: [22.30747, 0.05827274, 0.22249196]]\nBatch: 2833, [Full Discriminator :: Loss: 0.2568172812461853], [ Generator :: Loss: [15.852631, 0.5066939, 0.15345937]]\nBatch: 2834, [Full Discriminator :: Loss: 0.07760299742221832], [ Generator :: Loss: [17.742182, 0.13185298, 0.1761033]]\nBatch: 2835, [Full Discriminator :: Loss: 0.06993843615055084], [ Generator :: Loss: [12.134445, 0.07585322, 0.12058592]]\nBatch: 2836, [Full Discriminator :: Loss: 0.03624905273318291], [ Generator :: Loss: [15.851648, 0.03983876, 0.1581181]]\nBatch: 2837, [Full Discriminator :: Loss: 0.24726502597332], [ Generator :: Loss: [16.260382, 0.072781526, 0.16187601]]\nBatch: 2838, [Full Discriminator :: Loss: 0.1107008308172226], [ Generator :: Loss: [10.418861, 0.10123201, 0.103176296]]\nBatch: 2839, [Full Discriminator :: Loss: 0.041219569742679596], [ Generator :: Loss: [9.96839, 0.21772638, 0.097506635]]\nBatch: 2840, [Full Discriminator :: Loss: 0.04196785390377045], [ Generator :: Loss: [13.971076, 0.023915369, 0.1394716]]\nBatch: 2841, [Full Discriminator :: Loss: 0.067339688539505], [ Generator :: Loss: [15.802682, 0.03919356, 0.15763488]]\nBatch: 2842, [Full Discriminator :: Loss: 0.044960930943489075], [ Generator :: Loss: [17.457582, 0.04226022, 0.17415321]]\nBatch: 2843, [Full Discriminator :: Loss: 0.03855201229453087], [ Generator :: Loss: [10.064637, 0.08129319, 0.09983344]]\nBatch: 2844, [Full Discriminator :: Loss: 0.05590197443962097], [ Generator :: Loss: [15.13391, 0.044748478, 0.15089162]]\nBatch: 2845, [Full Discriminator :: Loss: 0.11919943988323212], [ Generator :: Loss: [18.047724, 0.11075958, 0.17936964]]\nBatch: 2846, [Full Discriminator :: Loss: 0.07732929289340973], [ Generator :: Loss: [13.492076, 0.25826818, 0.13233808]]\nBatch: 2847, [Full Discriminator :: Loss: 0.20330463349819183], [ Generator :: Loss: [18.82153, 0.15331727, 0.18668213]]\nBatch: 2848, [Full Discriminator :: Loss: 0.28978827595710754], [ Generator :: Loss: [16.607891, 0.21609819, 0.16391793]]\nBatch: 2849, [Full Discriminator :: Loss: 0.12994752824306488], [ Generator :: Loss: [15.050771, 0.31892595, 0.14731845]]\nBatch: 2850, [Full Discriminator :: Loss: 0.07074521481990814], [ Generator :: Loss: [17.837488, 0.22956505, 0.17607924]]\nBatch: 2851, [Full Discriminator :: Loss: 0.05008397251367569], [ Generator :: Loss: [10.2811775, 0.108902775, 0.10172275]]\nBatch: 2852, [Full Discriminator :: Loss: 0.0892152190208435], [ Generator :: Loss: [16.236027, 0.06405093, 0.16171977]]\nBatch: 2853, [Full Discriminator :: Loss: 0.0836145281791687], [ Generator :: Loss: [22.421782, 0.07221283, 0.22349569]]\nBatch: 2854, [Full Discriminator :: Loss: 0.27024999260902405], [ Generator :: Loss: [17.687443, 0.4701188, 0.17217323]]\nBatch: 2855, [Full Discriminator :: Loss: 0.18087439239025116], [ Generator :: Loss: [13.113136, 0.49129578, 0.12621841]]\nBatch: 2856, [Full Discriminator :: Loss: 0.32720986008644104], [ Generator :: Loss: [16.97099, 0.48629856, 0.1648469]]\nBatch: 2857, [Full Discriminator :: Loss: 0.09446783363819122], [ Generator :: Loss: [13.05718, 0.26430944, 0.1279287]]\nBatch: 2858, [Full Discriminator :: Loss: 0.299459308385849], [ Generator :: Loss: [21.360865, 0.45552704, 0.20905338]]\nBatch: 2859, [Full Discriminator :: Loss: 0.0924849733710289], [ Generator :: Loss: [12.754677, 0.3474405, 0.12407236]]\nBatch: 2860, [Full Discriminator :: Loss: 0.23711653053760529], [ Generator :: Loss: [13.469259, 0.27019173, 0.13199067]]\nBatch: 2861, [Full Discriminator :: Loss: 0.07810661196708679], [ Generator :: Loss: [13.58925, 0.08010565, 0.13509144]]\nBatch: 2862, [Full Discriminator :: Loss: 0.2749326229095459], [ Generator :: Loss: [13.985471, 0.32097536, 0.13664496]]\nBatch: 2863, [Full Discriminator :: Loss: 0.26288682222366333], [ Generator :: Loss: [17.57093, 0.41080466, 0.17160127]]\nBatch: 2864, [Full Discriminator :: Loss: 0.07608339935541153], [ Generator :: Loss: [20.783644, 0.3632255, 0.20420417]]\nBatch: 2865, [Full Discriminator :: Loss: 0.34696513414382935], [ Generator :: Loss: [15.407762, 0.10016592, 0.15307595]]\nBatch: 2866, [Full Discriminator :: Loss: 0.2006153166294098], [ Generator :: Loss: [20.750608, 0.24047318, 0.20510136]]\nBatch: 2867, [Full Discriminator :: Loss: 0.6098794341087341], [ Generator :: Loss: [19.64532, 0.40250838, 0.19242813]]\nBatch: 2868, [Full Discriminator :: Loss: 0.22960087656974792], [ Generator :: Loss: [17.96466, 0.33538103, 0.1762928]]\nBatch: 2869, [Full Discriminator :: Loss: 0.08354274183511734], [ Generator :: Loss: [20.180054, 0.46434855, 0.19715706]]\nBatch: 2870, [Full Discriminator :: Loss: 0.07749434560537338], [ Generator :: Loss: [19.666878, 0.17528838, 0.19491589]]\nBatch: 2871, [Full Discriminator :: Loss: 0.1102374941110611], [ Generator :: Loss: [22.33519, 0.21805602, 0.22117135]]\nBatch: 2872, [Full Discriminator :: Loss: 0.18407335877418518], [ Generator :: Loss: [21.642378, 0.10902618, 0.21533352]]\nBatch: 2873, [Full Discriminator :: Loss: 0.08534665405750275], [ Generator :: Loss: [16.96566, 0.15083766, 0.16814823]]\nBatch: 2874, [Full Discriminator :: Loss: 0.10516408085823059], [ Generator :: Loss: [17.779858, 0.13444343, 0.17645414]]\nBatch: 2875, [Full Discriminator :: Loss: 0.35609129071235657], [ Generator :: Loss: [20.967766, 0.25790107, 0.20709865]]\nBatch: 2876, [Full Discriminator :: Loss: 0.1271233856678009], [ Generator :: Loss: [20.17299, 0.20237263, 0.19970618]]\nBatch: 2877, [Full Discriminator :: Loss: 0.16479289531707764], [ Generator :: Loss: [11.510368, 0.28119895, 0.1122917]]\nBatch: 2878, [Full Discriminator :: Loss: 0.10783383250236511], [ Generator :: Loss: [18.097275, 0.16256043, 0.17934716]]\nBatch: 2879, [Full Discriminator :: Loss: 0.1402645856142044], [ Generator :: Loss: [19.947668, 0.2830103, 0.19664657]]\nBatch: 2880, [Full Discriminator :: Loss: 0.09218978136777878], [ Generator :: Loss: [22.945707, 0.27534437, 0.22670363]]\nBatch: 2881, [Full Discriminator :: Loss: 0.05416198819875717], [ Generator :: Loss: [11.970677, 0.22601281, 0.117446646]]\nBatch: 2882, [Full Discriminator :: Loss: 0.17833639681339264], [ Generator :: Loss: [18.363684, 0.13091902, 0.18232764]]\nBatch: 2883, [Full Discriminator :: Loss: 0.042607247829437256], [ Generator :: Loss: [8.719753, 0.07485384, 0.08644899]]\nBatch: 2884, [Full Discriminator :: Loss: 0.12298865616321564], [ Generator :: Loss: [11.702651, 0.12357744, 0.11579074]]\nBatch: 2885, [Full Discriminator :: Loss: 0.14902396500110626], [ Generator :: Loss: [13.376583, 0.29021445, 0.13086368]]\nBatch: 2886, [Full Discriminator :: Loss: 0.0526469387114048], [ Generator :: Loss: [18.54441, 0.17436394, 0.18370047]]\nBatch: 2887, [Full Discriminator :: Loss: 0.04918167367577553], [ Generator :: Loss: [15.4394245, 0.07477507, 0.1536465]]\nBatch: 2888, [Full Discriminator :: Loss: 0.15838538110256195], [ Generator :: Loss: [22.195723, 0.14559151, 0.2205013]]\nBatch: 2889, [Full Discriminator :: Loss: 0.21348309516906738], [ Generator :: Loss: [16.570692, 0.14662679, 0.16424064]]\nBatch: 2890, [Full Discriminator :: Loss: 0.49887174367904663], [ Generator :: Loss: [14.983032, 0.19772428, 0.14785308]]\nBatch: 2891, [Full Discriminator :: Loss: 0.07274709641933441], [ Generator :: Loss: [17.611576, 0.3499174, 0.1726166]]\nBatch: 2892, [Full Discriminator :: Loss: 0.2575736939907074], [ Generator :: Loss: [16.444263, 0.4536092, 0.15990655]]\nBatch: 2893, [Full Discriminator :: Loss: 0.07628369331359863], [ Generator :: Loss: [31.09845, 0.30331543, 0.30795133]]\nBatch: 2894, [Full Discriminator :: Loss: 0.04029129073023796], [ Generator :: Loss: [13.51724, 0.0481482, 0.13469091]]\nBatch: 2895, [Full Discriminator :: Loss: 0.04614615440368652], [ Generator :: Loss: [17.467709, 0.044628635, 0.1742308]]\nBatch: 2896, [Full Discriminator :: Loss: 0.051881421357393265], [ Generator :: Loss: [12.972563, 0.07417147, 0.12898391]]\nBatch: 2897, [Full Discriminator :: Loss: 0.03466646373271942], [ Generator :: Loss: [14.588113, 0.057493113, 0.1453062]]\nBatch: 2898, [Full Discriminator :: Loss: 0.0718243271112442], [ Generator :: Loss: [20.951063, 0.061388575, 0.20889676]]\nBatch: 2899, [Full Discriminator :: Loss: 0.04304606840014458], [ Generator :: Loss: [11.319104, 0.073204845, 0.11245899]]\nBatch: 2900, [Full Discriminator :: Loss: 0.03052375838160515], [ Generator :: Loss: [13.987734, 0.066213675, 0.1392152]]\nBatch: 2901, [Full Discriminator :: Loss: 0.04755299538373947], [ Generator :: Loss: [15.296968, 0.109417334, 0.15187551]]\nBatch: 2902, [Full Discriminator :: Loss: 0.16478464007377625], [ Generator :: Loss: [15.509286, 0.104271986, 0.15405014]]\nBatch: 2903, [Full Discriminator :: Loss: 0.06642481684684753], [ Generator :: Loss: [15.80609, 0.2779489, 0.15528141]]\nBatch: 2904, [Full Discriminator :: Loss: 0.0478103831410408], [ Generator :: Loss: [18.15659, 0.27764487, 0.17878945]]\nBatch: 2905, [Full Discriminator :: Loss: 0.20379529893398285], [ Generator :: Loss: [21.149332, 0.26374635, 0.20885587]]\nBatch: 2906, [Full Discriminator :: Loss: 0.5619357228279114], [ Generator :: Loss: [22.186773, 0.18839753, 0.21998374]]\nBatch: 2907, [Full Discriminator :: Loss: 0.6069546341896057], [ Generator :: Loss: [21.390684, 0.4182478, 0.20972437]]\nBatch: 2908, [Full Discriminator :: Loss: 0.28384873270988464], [ Generator :: Loss: [16.565336, 0.32000923, 0.16245326]]\nBatch: 2909, [Full Discriminator :: Loss: 0.38592514395713806], [ Generator :: Loss: [10.44429, 0.20936412, 0.10234927]]\nBatch: 2910, [Full Discriminator :: Loss: 0.18375369906425476], [ Generator :: Loss: [19.473074, 0.32166606, 0.19151407]]\nBatch: 2911, [Full Discriminator :: Loss: 0.10601477324962616], [ Generator :: Loss: [12.346429, 0.105946824, 0.12240482]]\nBatch: 2912, [Full Discriminator :: Loss: 0.20505550503730774], [ Generator :: Loss: [16.684425, 0.12530681, 0.16559118]]\nBatch: 2913, [Full Discriminator :: Loss: 0.043534647673368454], [ Generator :: Loss: [11.800024, 0.095136076, 0.11704888]]\nBatch: 2914, [Full Discriminator :: Loss: 0.039640773087739944], [ Generator :: Loss: [26.937798, 0.10565066, 0.26832148]]\nBatch: 2915, [Full Discriminator :: Loss: 0.2365933060646057], [ Generator :: Loss: [13.833159, 0.17781463, 0.13655345]]\nBatch: 2916, [Full Discriminator :: Loss: 0.045193471014499664], [ Generator :: Loss: [13.3955965, 0.16401379, 0.13231583]]\nBatch: 2917, [Full Discriminator :: Loss: 0.264955997467041], [ Generator :: Loss: [20.040443, 0.091116264, 0.19949327]]\nBatch: 2918, [Full Discriminator :: Loss: 0.06487468630075455], [ Generator :: Loss: [15.539812, 0.19244447, 0.15347368]]\nBatch: 2919, [Full Discriminator :: Loss: 0.05313625931739807], [ Generator :: Loss: [12.217472, 0.13788494, 0.12079587]]\nBatch: 2920, [Full Discriminator :: Loss: 0.16790124773979187], [ Generator :: Loss: [16.350046, 0.18220559, 0.1616784]]\nBatch: 2921, [Full Discriminator :: Loss: 0.3154495656490326], [ Generator :: Loss: [17.467537, 0.29525322, 0.17172283]]\nBatch: 2922, [Full Discriminator :: Loss: 0.03906440734863281], [ Generator :: Loss: [31.243423, 0.16076235, 0.3108266]]\nBatch: 2923, [Full Discriminator :: Loss: 0.38057848811149597], [ Generator :: Loss: [17.845385, 0.272616, 0.1757277]]\nBatch: 2924, [Full Discriminator :: Loss: 0.0501997247338295], [ Generator :: Loss: [15.652763, 0.110396214, 0.15542367]]\nBatch: 2925, [Full Discriminator :: Loss: 0.5161980986595154], [ Generator :: Loss: [11.531591, 0.10058425, 0.11431007]]\nBatch: 2926, [Full Discriminator :: Loss: 0.04256584495306015], [ Generator :: Loss: [17.68694, 0.09394714, 0.17592993]]\nBatch: 2927, [Full Discriminator :: Loss: 0.021056413650512695], [ Generator :: Loss: [12.017333, 0.052476585, 0.11964856]]\nBatch: 2928, [Full Discriminator :: Loss: 0.04648587480187416], [ Generator :: Loss: [20.446148, 0.057464562, 0.20388684]]\nBatch: 2929, [Full Discriminator :: Loss: 0.0701860710978508], [ Generator :: Loss: [20.34672, 0.03250402, 0.20314217]]\nBatch: 2930, [Full Discriminator :: Loss: 0.3413301110267639], [ Generator :: Loss: [13.891533, 0.14126603, 0.13750267]]\nBatch: 2931, [Full Discriminator :: Loss: 0.22618703544139862], [ Generator :: Loss: [12.434651, 0.31307408, 0.121215776]]\nBatch: 2932, [Full Discriminator :: Loss: 0.06444297730922699], [ Generator :: Loss: [22.14468, 0.11648983, 0.2202819]]\nBatch: 2933, [Full Discriminator :: Loss: 0.20056751370429993], [ Generator :: Loss: [12.536932, 0.2683407, 0.12268591]]\nBatch: 2934, [Full Discriminator :: Loss: 0.12395402789115906], [ Generator :: Loss: [17.048552, 0.10116491, 0.16947386]]\nBatch: 2935, [Full Discriminator :: Loss: 0.036104507744312286], [ Generator :: Loss: [13.452913, 0.04913548, 0.13403778]]\nBatch: 2936, [Full Discriminator :: Loss: 0.03780811280012131], [ Generator :: Loss: [16.231113, 0.07914391, 0.1615197]]\nBatch: 2937, [Full Discriminator :: Loss: 0.06509223580360413], [ Generator :: Loss: [13.86894, 0.01740205, 0.13851538]]\nBatch: 2938, [Full Discriminator :: Loss: 0.06311280280351639], [ Generator :: Loss: [12.9023695, 0.06602687, 0.12836343]]\nBatch: 2939, [Full Discriminator :: Loss: 0.05788843333721161], [ Generator :: Loss: [22.49723, 0.095680155, 0.2240155]]\nBatch: 2940, [Full Discriminator :: Loss: 0.08915664255619049], [ Generator :: Loss: [23.894066, 0.12285267, 0.23771213]]\nBatch: 2941, [Full Discriminator :: Loss: 0.10509255528450012], [ Generator :: Loss: [15.367858, 0.14263609, 0.15225221]]\nBatch: 2942, [Full Discriminator :: Loss: 0.06954652816057205], [ Generator :: Loss: [15.431353, 0.059794288, 0.15371558]]\nBatch: 2943, [Full Discriminator :: Loss: 0.05450965464115143], [ Generator :: Loss: [23.507376, 0.11467613, 0.23392701]]\nBatch: 2944, [Full Discriminator :: Loss: 0.30699944496154785], [ Generator :: Loss: [17.379583, 0.3851745, 0.1699441]]\nBatch: 2945, [Full Discriminator :: Loss: 0.16488468647003174], [ Generator :: Loss: [16.64404, 0.18104392, 0.16462995]]\nBatch: 2946, [Full Discriminator :: Loss: 0.13412848114967346], [ Generator :: Loss: [12.467125, 0.18336336, 0.12283762]]\nBatch: 2947, [Full Discriminator :: Loss: 0.12824560701847076], [ Generator :: Loss: [15.006159, 0.23277962, 0.1477338]]\nBatch: 2948, [Full Discriminator :: Loss: 0.057778600603342056], [ Generator :: Loss: [16.813833, 0.117373854, 0.16696459]]\nBatch: 2949, [Full Discriminator :: Loss: 0.5150095224380493], [ Generator :: Loss: [13.405628, 0.140276, 0.13265352]]\nBatch: 2950, [Full Discriminator :: Loss: 0.16188308596611023], [ Generator :: Loss: [16.130602, 0.49911147, 0.1563149]]\nBatch: 2951, [Full Discriminator :: Loss: 0.22853894531726837], [ Generator :: Loss: [12.250764, 0.41451856, 0.11836246]]\nBatch: 2952, [Full Discriminator :: Loss: 0.07782071828842163], [ Generator :: Loss: [13.509764, 0.18749069, 0.13322273]]\nBatch: 2953, [Full Discriminator :: Loss: 0.052746593952178955], [ Generator :: Loss: [10.629594, 0.09349825, 0.105360955]]\nBatch: 2954, [Full Discriminator :: Loss: 0.2741056978702545], [ Generator :: Loss: [12.575565, 0.21472025, 0.123608455]]\nBatch: 2955, [Full Discriminator :: Loss: 0.047282714396715164], [ Generator :: Loss: [14.451159, 0.22769946, 0.1422346]]\nBatch: 2956, [Full Discriminator :: Loss: 0.23691803216934204], [ Generator :: Loss: [9.710425, 0.20477799, 0.095056474]]\nBatch: 2957, [Full Discriminator :: Loss: 0.04616020247340202], [ Generator :: Loss: [15.585565, 0.30053425, 0.1528503]]\nBatch: 2958, [Full Discriminator :: Loss: 0.16029581427574158], [ Generator :: Loss: [14.908189, 0.11748655, 0.14790702]]\nBatch: 2959, [Full Discriminator :: Loss: 0.08122273534536362], [ Generator :: Loss: [22.580595, 0.10088798, 0.22479708]]\nBatch: 2960, [Full Discriminator :: Loss: 0.3122673034667969], [ Generator :: Loss: [14.21419, 0.18815234, 0.14026037]]\nBatch: 2961, [Full Discriminator :: Loss: 0.09957367181777954], [ Generator :: Loss: [10.929109, 0.18175583, 0.10747352]]\nBatch: 2962, [Full Discriminator :: Loss: 0.24951067566871643], [ Generator :: Loss: [13.749429, 0.07737188, 0.13672057]]\nBatch: 2963, [Full Discriminator :: Loss: 0.1356252133846283], [ Generator :: Loss: [26.4205, 0.029554298, 0.26390946]]\nBatch: 2964, [Full Discriminator :: Loss: 0.07183133810758591], [ Generator :: Loss: [16.712246, 0.047211677, 0.16665034]]\nBatch: 2965, [Full Discriminator :: Loss: 0.054041631519794464], [ Generator :: Loss: [12.782992, 0.06232757, 0.12720665]]\nBatch: 2966, [Full Discriminator :: Loss: 0.058366939425468445], [ Generator :: Loss: [22.195147, 0.08959073, 0.22105557]]\nBatch: 2967, [Full Discriminator :: Loss: 0.05255769565701485], [ Generator :: Loss: [14.599023, 0.073799975, 0.14525223]]\nBatch: 2968, [Full Discriminator :: Loss: 0.047952208667993546], [ Generator :: Loss: [12.698922, 0.11206135, 0.1258686]]\nBatch: 2969, [Full Discriminator :: Loss: 0.10164476931095123], [ Generator :: Loss: [15.298413, 0.18961574, 0.15108797]]\nBatch: 2970, [Full Discriminator :: Loss: 0.08228891342878342], [ Generator :: Loss: [16.86277, 0.18403223, 0.16678739]]\nBatch: 2971, [Full Discriminator :: Loss: 0.1588113158941269], [ Generator :: Loss: [13.82098, 0.20282637, 0.13618153]]\nBatch: 2972, [Full Discriminator :: Loss: 0.10770729184150696], [ Generator :: Loss: [17.01661, 0.3884423, 0.16628166]]\nBatch: 2973, [Full Discriminator :: Loss: 0.14281268417835236], [ Generator :: Loss: [12.764048, 0.14949474, 0.12614553]]\nBatch: 2974, [Full Discriminator :: Loss: 0.07598687708377838], [ Generator :: Loss: [14.248111, 0.16100796, 0.14087103]]\nEpoch: 0, [Full Discriminator :: Loss:0.07598687708377838], [ Generator :: Loss: [14.248111, 0.16100796, 0.14087103]]\n"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}