# CycleGAN: Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Netwoks

[CycleGANs](https://arxiv.org/pdf/1703.10593.pdf) were proposed by Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A. CycleGANs are a novel approach for translating an image from a source domain A to a target domain B. One of the cool feature of CycleGANs is that it doesn’t require paired training data to produce stunning style transfer results. 

In many style transfer applications, paired data is a required for the training.
<p align="center">
  <img src="./paired_data_sample.png" width="400px" title="Paired Data">
</p>

CycleGAN doesn’t require paired data input to train a models.
<p align="center">
  <img src="./unpaired_data_sample.png" width="400px" title="Unpaired Data">
</p>

