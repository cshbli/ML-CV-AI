{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kcPxlh4SsOVz"
   },
   "source": [
    "# CycleGAN with Keras on summer2winter_yosemite Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to note that we are using a keras_contributer layer, the InstanceNormalization layer. This layer is used in the original CycleGAN paper (https://arxiv.org/pdf/1703.10593.pdf) and it is an open source implementation.\n",
    "\n",
    "Instance Normalization (IN) is Batch Normalization (BN) per sample of data (IN is BN per image or per feature). \n",
    "* In style transfer, it's important to normalize the contrast per sample not per batch. \n",
    "\n",
    "We need to install keras-contrib, before using Instance Normalization. \n",
    "\n",
    " * pip3 install git+https://www.github.com/keras-team/keras-contrib.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install and Imports the required module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "colab_type": "code",
    "id": "tzFyPCAtsOV2",
    "outputId": "2b6c41af-6d8d-4f51-dc30-b7a5f616fea8"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from random import randint\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import keras.backend as K\n",
    "from keras import initializers\n",
    "from keras.utils import plot_model\n",
    "from keras.layers.core import Activation\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.optimizers import Adam, SGD,Nadam, Adamax\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, MaxPooling2D,Deconvolution2D\n",
    "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, BatchNormalization, Lambda, Concatenate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fn2futVhsOVq"
   },
   "source": [
    "#### CycleGAN datasets can be downloaded from below link.                \n",
    "https://people.eecs.berkeley.edu/~taesung_park/CycleGAN/datasets/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-yFkP_9NAFcA"
   },
   "source": [
    "In CycleGAN we will downsample for a few blocks then upsample. We will also use a new layer called InstanceNormalization that was used by authors to enforce better training for style transfer.\n",
    "* The first part of the model involves 2D convolutions with this InstanceNormalization layer.\n",
    "* The upsample blocks are similar to the downsample but bring us back up to the original resolution of our images.\n",
    "* The last part of the generator model method is the output layer and the structure of this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9zKg_BVgsOWf"
   },
   "outputs": [],
   "source": [
    "class Generator(object):\n",
    "    def __init__(self, width = 28, height= 28, channels = 1):\n",
    "        \n",
    "        self.W = width\n",
    "        self.H = height\n",
    "        self.C = channels\n",
    "        self.SHAPE = (width,height,channels)\n",
    "\n",
    "        self.Generator = self.model()\n",
    "        self.OPTIMIZER = Adam(lr=2e-4, beta_1=0.5,decay=1e-5)\n",
    "        self.Generator.compile(loss='binary_crossentropy', optimizer=self.OPTIMIZER,metrics=['accuracy'])\n",
    "\n",
    "        # self.save_model()\n",
    "        self.summary()\n",
    "\n",
    "    def model(self):\n",
    "        input_layer = Input(shape=self.SHAPE)\n",
    "        \n",
    "        down_1 = Convolution2D(64  , kernel_size=4, strides=2, padding='same',activation=LeakyReLU(alpha=0.2))(input_layer)\n",
    "        norm_1 = InstanceNormalization()(down_1)\n",
    "\n",
    "        down_2 = Convolution2D(64*2, kernel_size=4, strides=2, padding='same',activation=LeakyReLU(alpha=0.2))(norm_1)\n",
    "        norm_2 = InstanceNormalization()(down_2)\n",
    "\n",
    "        down_3 = Convolution2D(64*4, kernel_size=4, strides=2, padding='same',activation=LeakyReLU(alpha=0.2))(norm_2)\n",
    "        norm_3 = InstanceNormalization()(down_3)\n",
    "\n",
    "        down_4 = Convolution2D(64*8, kernel_size=4, strides=2, padding='same',activation=LeakyReLU(alpha=0.2))(norm_3)\n",
    "        norm_4 = InstanceNormalization()(down_4)\n",
    "\n",
    "\n",
    "        upsample_1 = UpSampling2D()(norm_4)\n",
    "        up_conv_1 = Convolution2D(64*4, kernel_size=4, strides=1, padding='same',activation='relu')(upsample_1)\n",
    "        norm_up_1 = InstanceNormalization()(up_conv_1)\n",
    "        add_skip_1 = Concatenate()([norm_up_1,norm_3])\n",
    "\n",
    "        upsample_2 = UpSampling2D()(add_skip_1)\n",
    "        up_conv_2 = Convolution2D(64*2, kernel_size=4, strides=1, padding='same',activation='relu')(upsample_2)\n",
    "        norm_up_2 = InstanceNormalization()(up_conv_2)\n",
    "        add_skip_2 = Concatenate()([norm_up_2,norm_2])\n",
    "\n",
    "        upsample_3 = UpSampling2D()(add_skip_2)\n",
    "        up_conv_3 = Convolution2D(64, kernel_size=4, strides=1, padding='same',activation='relu')(upsample_3)\n",
    "        norm_up_3 = InstanceNormalization()(up_conv_3)\n",
    "        add_skip_3 = Concatenate()([norm_up_3,norm_1])\n",
    "\n",
    "        last_upsample = UpSampling2D()(add_skip_3)\n",
    "        output_layer = Convolution2D(3, kernel_size=4, strides=1, padding='same',activation='tanh')(last_upsample)\n",
    "        \n",
    "        return Model(input_layer,output_layer)\n",
    "\n",
    "    def summary(self):\n",
    "        return self.Generator.summary()\n",
    "\n",
    "    def save_model(self):\n",
    "        plot_model(self.Generator.model, to_file='./data/Generator_Model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MRXWKQcAsOWo"
   },
   "source": [
    "* Discriminator has a few 2D convolutional layers until we get to our output layer.\n",
    "* The final few layers will bring us back to our output variable and appropriately flatten it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9G2qYJpUsOWw"
   },
   "outputs": [],
   "source": [
    "class Discriminator(object):\n",
    "    def __init__(self, width = 28, height= 28, channels = 1):\n",
    "        self.W = width\n",
    "        self.H = height\n",
    "        self.C = channels\n",
    "        self.CAPACITY = width*height*channels\n",
    "        self.SHAPE = (width,height,channels)\n",
    "        \n",
    "        self.Discriminator = self.model()\n",
    "        self.OPTIMIZER = Adam(lr=2e-4, beta_1=0.5,decay=1e-5)\n",
    "        self.Discriminator.compile(loss='mse', optimizer=self.OPTIMIZER, metrics=['accuracy'] )\n",
    "\n",
    "        # self.save_model()\n",
    "        self.summary()\n",
    "\n",
    "    def model(self):\n",
    "        input_layer = Input(self.SHAPE)\n",
    "\n",
    "        up_layer_1 = Convolution2D(64, kernel_size=4, strides=2, padding='same',activation=LeakyReLU(alpha=0.2))(input_layer)\n",
    "\n",
    "        up_layer_2 = Convolution2D(64*2, kernel_size=4, strides=2, padding='same',activation=LeakyReLU(alpha=0.2))(up_layer_1)\n",
    "        norm_layer_1 = InstanceNormalization()(up_layer_2)\n",
    "\n",
    "        up_layer_3 = Convolution2D(64*4, kernel_size=4, strides=2, padding='same',activation=LeakyReLU(alpha=0.2))(norm_layer_1)\n",
    "        norm_layer_2 = InstanceNormalization()(up_layer_3)\n",
    "\n",
    "        up_layer_4 = Convolution2D(64*8, kernel_size=4, strides=2, padding='same',activation=LeakyReLU(alpha=0.2))(norm_layer_2)\n",
    "        norm_layer_3 =InstanceNormalization()(up_layer_4)\n",
    "\n",
    "        output_layer = Convolution2D(1, kernel_size=4, strides=1, padding='same')(norm_layer_3)\n",
    "        output_layer_1 = Flatten()(output_layer)\n",
    "        output_layer_2 = Dense(1, activation='sigmoid')(output_layer_1)\n",
    "        \n",
    "        return Model(input_layer,output_layer_2)\n",
    "\n",
    "    def summary(self):\n",
    "        return self.Discriminator.summary()\n",
    "\n",
    "    def save_model(self):\n",
    "        plot_model(self.Discriminator.model, to_file='./data/Discriminator_Model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T3_oRxhnsOW4"
   },
   "source": [
    "* The GAN model will have six models in adversarial training mode.\n",
    "* lambda _cycle and lambda_id refer to the values of the loss functions for the X to Y generation and X to Y to X reconstruction generation, respectively. The lambda_id parameter should be 10% (according to the paper) of the lambda_cycle variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G-XLZiEWsOXA"
   },
   "outputs": [],
   "source": [
    "class GAN(object):\n",
    "    def __init__(self, model_inputs=[],model_outputs=[],lambda_cycle=10.0,lambda_id=1.0):\n",
    "        self.OPTIMIZER = SGD(lr=2e-4,nesterov=True)\n",
    "        # self.inputs are represented by an array of two Keras input classes instantiated in the training class and passed to the GAN class.\n",
    "        self.inputs = model_inputs\n",
    "        # Create a model with the input and output passed from the training class.\n",
    "        self.outputs = model_outputs\n",
    "        self.gan_model = Model(self.inputs,self.outputs)\n",
    "        self.OPTIMIZER = Adam(lr=2e-4, beta_1=0.5)\n",
    "        # The output array is six models, four generators, and two discriminators in an adversarial setup.\n",
    "        self.gan_model.compile(loss=['mse', 'mse',\n",
    "                                    'mae', 'mae',\n",
    "                                    'mae', 'mae'],\n",
    "                            loss_weights=[  1, 1,\n",
    "                                            lambda_cycle, lambda_cycle,\n",
    "                                            lambda_id, lambda_id ],\n",
    "                            optimizer=self.OPTIMIZER)\n",
    "        # self.save_model()\n",
    "        self.summary()\n",
    "\n",
    "    def model(self):\n",
    "        model = Model()\n",
    "        return model\n",
    "\n",
    "    def summary(self):\n",
    "        return self.gan_model.summary()\n",
    "\n",
    "    def save_model(self):\n",
    "        plot_model(self.gan_model.model, to_file='./data/GAN_Model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yiWw7b40sOXt"
   },
   "source": [
    "Trainer class. We now have two separate folders for both a training and test setup. We will train a model on one dataset and demonstrate the results of the generator on the test dataset. This makes sure that we aren't overfitting to the relationship we are learning between the train_A and train_B datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3etQMuj0sOX7"
   },
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, height = 64, width = 64, epochs = 50000, batch = 32, checkpoint = 50, train_data_path_A = '',train_data_path_B = '',test_data_path_A='',test_data_path_B='',lambda_cycle=10.0,lambda_id=1.0):\n",
    "        self.EPOCHS = epochs\n",
    "        self.BATCH = batch\n",
    "        self.RESIZE_HEIGHT = height\n",
    "        self.RESIZE_WIDTH = width\n",
    "        self.CHECKPOINT = checkpoint\n",
    "        # Load all of the data into its respective class variables\n",
    "        self.X_train_A, self.H_A, self.W_A, self.C_A = self.load_data(train_data_path_A)\n",
    "        self.X_train_B, self.H_B, self.W_B, self.C_B  = self.load_data(train_data_path_B)\n",
    "        self.X_test_A, self.H_A_test, self.W_A_test, self.C_A_test = self.load_data(test_data_path_A)\n",
    "        self.X_test_B, self.H_B_test, self.W_B_test, self.C_B_test  = self.load_data(test_data_path_B)\n",
    "         \n",
    "        '''We need the generators that go from A to B and from B to A. \n",
    "        The instantiation of these models is direct.'''\n",
    "        self.generator_A_to_B = Generator(height=self.H_A, width=self.W_A, channels=self.C_A)\n",
    "        self.generator_B_to_A = Generator(height=self.H_B, width=self.W_B, channels=self.C_B)\n",
    "        \n",
    "        #  following lines to instantiation in the class definition for training\n",
    "        '''We need to make sure we have the original A and B images stored as the Input class from Keras. \n",
    "        Variables orig_A and orig_B are the input values shared among the next three components.''' \n",
    "        self.orig_A = Input(shape=(self.W_A, self.H_A, self.C_A))\n",
    "        self.orig_B = Input(shape=(self.W_B, self.H_B, self.C_B))\n",
    "        '''fake_A and fake_B are the generators that take us from one style to the other and produce \n",
    "        an image with the translated style. Hence, this is why we say they are fake.'''\n",
    "        self.fake_B = self.generator_A_to_B.Generator(self.orig_A)\n",
    "        self.fake_A = self.generator_B_to_A.Generator(self.orig_B)\n",
    "        '''reconstructed_A and reconstructed_B take the fake A and B images and retranslate \n",
    "        them into the original image style.'''\n",
    "        self.reconstructed_A = self.generator_B_to_A.Generator(self.fake_B)\n",
    "        self.reconstructed_B = self.generator_A_to_B.Generator(self.fake_A)\n",
    "        '''id_A and id_B are identity functions because they take in the original image and translate \n",
    "        back into the same style. Ideally, these functions would not apply any style changes to these images'''\n",
    "        self.id_A = self.generator_B_to_A.Generator(self.orig_A)\n",
    "        self.id_B = self.generator_A_to_B.Generator(self.orig_B)\n",
    "\n",
    "        '''We need our discriminators that evaluate both A and B images. \n",
    "        We also need a validity discriminator that checks the fake_A and fake_B generators'''\n",
    "        self.discriminator_A = Discriminator(height=self.H_A, width=self.W_A, channels=self.C_A)\n",
    "        self.discriminator_B = Discriminator(height=self.H_B, width=self.W_B, channels=self.C_B)\n",
    "        self.discriminator_A.trainable = False\n",
    "        self.discriminator_B.trainable = False\n",
    "        self.valid_A = self.discriminator_A.Discriminator(self.fake_A)\n",
    "        self.valid_B = self.discriminator_B.Discriminator(self.fake_B)\n",
    "\n",
    "        ''' we are able to simply pass all of the models to the GAN class \n",
    "        and it will construct our adversarial model'''\n",
    "        model_inputs  = [self.orig_A,self.orig_B]\n",
    "        model_outputs = [self.valid_A, self.valid_B,self.reconstructed_A,self.reconstructed_B,self.id_A, self.id_B]\n",
    "        self.gan = GAN(model_inputs=model_inputs,model_outputs=model_outputs,lambda_cycle=lambda_cycle,lambda_id=lambda_id)\n",
    "        \n",
    "    # The load_data function expects a string that represents the path to the folder and it'll read every image with a certain file ending within that folder.\n",
    "    def load_data(self,data_path,amount_of_data = 1.0):\n",
    "        listOFFiles = self.grabListOfFiles(data_path,extension=\"jpg\")\n",
    "        X_train = np.array(self.grabArrayOfImages(listOFFiles))\n",
    "        height, width, channels = np.shape(X_train[0])\n",
    "        X_train = X_train[:int(amount_of_data*float(len(X_train)))]\n",
    "        X_train = (X_train.astype(np.float32) - 127.5)/127.5\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "        return X_train, height, width, channels\n",
    "\n",
    "    def grabListOfFiles(self,startingDirectory,extension=\".webp\"):\n",
    "        listOfFiles = []\n",
    "        for file in os.listdir(startingDirectory):\n",
    "            if file.endswith(extension):\n",
    "                listOfFiles.append(os.path.join(startingDirectory, file))\n",
    "        return listOfFiles\n",
    "\n",
    "    def grabArrayOfImages(self,listOfFiles,gray=False):\n",
    "        imageArr = []\n",
    "        for f in listOfFiles:\n",
    "            if gray:\n",
    "                im = Image.open(f).convert(\"L\")\n",
    "            else:\n",
    "                im = Image.open(f).convert(\"RGB\")\n",
    "            im = im.resize((self.RESIZE_WIDTH,self.RESIZE_HEIGHT))\n",
    "            imData = np.asarray(im)\n",
    "            imageArr.append(imData)\n",
    "        return imageArr\n",
    "\n",
    "    '''we need to collect our data for our batch generator differently and \n",
    "    we need to train each one of the discriminators we just developed (four in total)'''\n",
    "    def train(self):\n",
    "        for e in range(self.EPOCHS):\n",
    "            b = 0\n",
    "            X_train_A_temp = deepcopy(self.X_train_A)\n",
    "            X_train_B_temp = deepcopy(self.X_train_B)\n",
    "            '''Because the batch represents a single image, it isn't strictly required that each domain \n",
    "            contain the same number of images. Now, this means that our while statement needs to take \n",
    "            into account that there is one folder smaller than the other. The epoch will end when \n",
    "            there are no more images in the smaller array of images between A and B.'''\n",
    "            while min(len(X_train_A_temp),len(X_train_B_temp))>self.BATCH:\n",
    "                # Keep track of Batches\n",
    "                b=b+1\n",
    "\n",
    "                # Train Discriminator\n",
    "                # Grab Real Images for this training batch\n",
    "                '''we need to have an A and B version of our batches'''\n",
    "                count_real_images = int(self.BATCH)\n",
    "                starting_indexs = randint(0, (min(len(X_train_A_temp),len(X_train_B_temp))-count_real_images))\n",
    "                real_images_raw_A = X_train_A_temp[ starting_indexs : (starting_indexs + count_real_images) ]\n",
    "                real_images_raw_B = X_train_B_temp[ starting_indexs : (starting_indexs + count_real_images) ]\n",
    "\n",
    "                # Delete the images used until we have none left\n",
    "                X_train_A_temp = np.delete(X_train_A_temp,range(starting_indexs,(starting_indexs + count_real_images)),0)\n",
    "                X_train_B_temp = np.delete(X_train_B_temp,range(starting_indexs,(starting_indexs + count_real_images)),0)\n",
    "                batch_A = real_images_raw_A.reshape( count_real_images, self.W_A, self.H_A, self.C_A )\n",
    "                batch_B = real_images_raw_B.reshape( count_real_images, self.W_B, self.H_B, self.C_B )\n",
    "\n",
    "                self.discriminator_A.Discriminator.trainable = True\n",
    "                self.discriminator_B.Discriminator.trainable = True\n",
    "                x_batch_A = batch_A\n",
    "                x_batch_B = batch_B\n",
    "                y_batch_A = np.ones([count_real_images,1])\n",
    "                y_batch_B = np.ones([count_real_images,1])\n",
    "                # Now, train the discriminator with this batch of reals\n",
    "                discriminator_loss_A_real = self.discriminator_A.Discriminator.train_on_batch(x_batch_A,y_batch_A)[0]\n",
    "                discriminator_loss_B_real = self.discriminator_B.Discriminator.train_on_batch(x_batch_B,y_batch_B)[0]\n",
    "\n",
    "                x_batch_B = self.generator_A_to_B.Generator.predict(batch_A)\n",
    "                x_batch_A = self.generator_B_to_A.Generator.predict(batch_B)\n",
    "                y_batch_A = np.zeros([self.BATCH,1])\n",
    "                y_batch_B = np.zeros([self.BATCH,1])\n",
    "                # Now, train the discriminator with this batch of fakes\n",
    "                discriminator_loss_A_fake = self.discriminator_A.Discriminator.train_on_batch(x_batch_A,y_batch_A)[0]\n",
    "                discriminator_loss_B_fake = self.discriminator_B.Discriminator.train_on_batch(x_batch_B,y_batch_B)[0]    \n",
    "\n",
    "                self.discriminator_A.Discriminator.trainable = False\n",
    "                self.discriminator_B.Discriminator.trainable = False\n",
    "\n",
    "                discriminator_loss_A = 0.5*(discriminator_loss_A_real + discriminator_loss_A_fake)\n",
    "                discriminator_loss_B = 0.5*(discriminator_loss_B_real + discriminator_loss_B_fake)\n",
    "            \n",
    "                # In practice, flipping the label when training the generator improves convergence\n",
    "                '''we introduce label noise into the training process with the development of the \n",
    "                batches for training the individual discriminators'''\n",
    "                if self.flipCoin(chance=0.9):\n",
    "                    y_generated_labels = np.ones([self.BATCH,1])\n",
    "                else:\n",
    "                    y_generated_labels = np.zeros([self.BATCH,1])\n",
    "                generator_loss = self.gan.gan_model.train_on_batch([x_batch_A, x_batch_B],\n",
    "                                                        [y_generated_labels, y_generated_labels,\n",
    "                                                        x_batch_A, x_batch_B,\n",
    "                                                        x_batch_A, x_batch_B])    \n",
    "\n",
    "                print ('Epoch: '+str(int(e))+' Batch: '+str(int(b))+', [Discriminator_A :: Loss: '+str(discriminator_loss_A)+'], [ Generator :: Loss: '+str(generator_loss)+']')\n",
    "                print ('Epoch: '+str(int(e))+' Batch: '+str(int(b))+', [Discriminator_B :: Loss: '+str(discriminator_loss_B)+'], [ Generator :: Loss: '+str(generator_loss)+']')\n",
    "                if b % self.CHECKPOINT == 0 :\n",
    "                    label = str(e)+'_'+str(b)\n",
    "                    self.plot_checkpoint(label)\n",
    "\n",
    "            print ('Epoch: '+str(int(e))+', [Discriminator_A :: Loss: '+str(discriminator_loss_A)+'], [ Generator :: Loss: '+str(generator_loss)+']')\n",
    "            print ('Epoch: '+str(int(e))+', [Discriminator_A :: Loss: '+str(discriminator_loss_B)+'], [ Generator :: Loss: '+str(generator_loss)+']')\n",
    "                        \n",
    "            #if e % self.CHECKPOINT == 0 :\n",
    "                #self.plot_checkpoint(e)\n",
    "        return\n",
    " \n",
    "    def flipCoin(self,chance=0.5):\n",
    "        return np.random.binomial(1, chance)\n",
    "\n",
    "    def plot_checkpoint(self,b):\n",
    "        orig_filename = \"./data/batch_check_\"+str(b)+\"_original.png\"\n",
    "\n",
    "        image_A = self.X_test_A[5]\n",
    "        image_A = np.reshape(image_A, [self.W_A_test,self.H_A_test,self.C_A_test])\n",
    "        print(\"Image_A shape: \" +str(np.shape(image_A)))\n",
    "        fake_B = self.generator_A_to_B.Generator.predict(image_A.reshape(1, self.W_A, self.H_A, self.C_A ))\n",
    "        fake_B = np.reshape(fake_B, [self.W_A_test,self.H_A_test,self.C_A_test])\n",
    "        print(\"fake_B shape: \" +str(np.shape(fake_B)))\n",
    "        reconstructed_A = self.generator_B_to_A.Generator.predict(fake_B.reshape(1, self.W_A, self.H_A, self.C_A ))\n",
    "        reconstructed_A = np.reshape(reconstructed_A, [self.W_A_test,self.H_A_test,self.C_A_test])\n",
    "        print(\"reconstructed_A shape: \" +str(np.shape(reconstructed_A)))\n",
    "        # from IPython import embed; embed()\n",
    "\n",
    "        checkpoint_images = np.array([image_A, fake_B, reconstructed_A])\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        checkpoint_images = 0.5 * checkpoint_images + 0.5\n",
    "\n",
    "        titles = ['Original', 'Translated', 'Reconstructed']\n",
    "        fig, axes = plt.subplots(1, 3)\n",
    "        for i in range(3):\n",
    "            image = checkpoint_images[i]\n",
    "            image = np.reshape(image, [self.H_A_test,self.W_A_test,self.C_A_test])\n",
    "            axes[i].imshow(image)\n",
    "            axes[i].set_title(titles[i])\n",
    "            axes[i].axis('off')\n",
    "        fig.savefig(\"./data/batch_check_\"+str(b)+\".png\")\n",
    "        plt.close('all')\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HBZxfB-OsOYD"
   },
   "source": [
    "Let's start training. Here I run for the 5 EPOCHS, for the better result the value of EPOCHS need to be more like around 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185881
    },
    "colab_type": "code",
    "id": "1-hl2-bHsOYL",
    "outputId": "953cddbb-539d-49b9-c1c5-c55a2dbffb6a",
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": ", [ Generator :: Loss: [1.2337908, 0.0, 0.0, 0.051689982, 0.05551316, 0.0928797, 0.06887975]]\nEpoch: 1 Batch: 1164, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [1.2337908, 0.0, 0.0, 0.051689982, 0.05551316, 0.0928797, 0.06887975]]\nEpoch: 1 Batch: 1165, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [2.2074807, 0.0, 0.0, 0.0880945, 0.100232266, 0.17189005, 0.15232302]]\nEpoch: 1 Batch: 1165, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [2.2074807, 0.0, 0.0, 0.0880945, 0.100232266, 0.17189005, 0.15232302]]\nEpoch: 1 Batch: 1166, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [2.1458535, 0.0, 0.0, 0.09191208, 0.09420764, 0.15146004, 0.13319644]]\nEpoch: 1 Batch: 1166, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [2.1458535, 0.0, 0.0, 0.09191208, 0.09420764, 0.15146004, 0.13319644]]\nEpoch: 1 Batch: 1167, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [1.755798, 0.0, 0.0, 0.06996672, 0.082161956, 0.12648922, 0.108022094]]\nEpoch: 1 Batch: 1167, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [1.755798, 0.0, 0.0, 0.06996672, 0.082161956, 0.12648922, 0.108022094]]\nEpoch: 1 Batch: 1168, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [2.5849059, 0.0, 0.0, 0.11240707, 0.11054026, 0.20882054, 0.14661202]]\nEpoch: 1 Batch: 1168, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [2.5849059, 0.0, 0.0, 0.11240707, 0.11054026, 0.20882054, 0.14661202]]\nEpoch: 1 Batch: 1169, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [2.1152594, 0.0, 0.0, 0.0816283, 0.098724484, 0.1583058, 0.15342575]]\nEpoch: 1 Batch: 1169, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [2.1152594, 0.0, 0.0, 0.0816283, 0.098724484, 0.1583058, 0.15342575]]\nEpoch: 1 Batch: 1170, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [1.3987417, 0.0, 0.0, 0.055049848, 0.064682595, 0.10200182, 0.09941538]]\nEpoch: 1 Batch: 1170, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [1.3987417, 0.0, 0.0, 0.055049848, 0.064682595, 0.10200182, 0.09941538]]\nEpoch: 1 Batch: 1171, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [1.7500777, 0.0, 0.0, 0.06709045, 0.08168416, 0.1331492, 0.12918237]]\nEpoch: 1 Batch: 1171, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [1.7500777, 0.0, 0.0, 0.06709045, 0.08168416, 0.1331492, 0.12918237]]\nEpoch: 1 Batch: 1172, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [1.7245482, 0.0, 0.0, 0.0565498, 0.09008896, 0.118189335, 0.13997123]]\nEpoch: 1 Batch: 1172, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [1.7245482, 0.0, 0.0, 0.0565498, 0.09008896, 0.118189335, 0.13997123]]\nEpoch: 1 Batch: 1173, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [1.2872034, 0.0, 0.0, 0.049718905, 0.056734458, 0.11557325, 0.107096575]]\nEpoch: 1 Batch: 1173, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [1.2872034, 0.0, 0.0, 0.049718905, 0.056734458, 0.11557325, 0.107096575]]\nEpoch: 1 Batch: 1174, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [1.3348365, 0.0, 0.0, 0.05275725, 0.05938317, 0.10198327, 0.11144895]]\nEpoch: 1 Batch: 1174, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [1.3348365, 0.0, 0.0, 0.05275725, 0.05938317, 0.10198327, 0.11144895]]\nEpoch: 1 Batch: 1175, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [2.3884192, 0.0, 0.0, 0.100873694, 0.10800217, 0.1313326, 0.16832769]]\nEpoch: 1 Batch: 1175, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [2.3884192, 0.0, 0.0, 0.100873694, 0.10800217, 0.1313326, 0.16832769]]\nEpoch: 1 Batch: 1176, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [2.7818208, 0.0, 0.0, 0.10548984, 0.1400545, 0.16939475, 0.15698256]]\nEpoch: 1 Batch: 1176, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [2.7818208, 0.0, 0.0, 0.10548984, 0.1400545, 0.16939475, 0.15698256]]\nEpoch: 1 Batch: 1177, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [2.190149, 0.0, 0.0, 0.07911168, 0.11176118, 0.14249292, 0.13892753]]\nEpoch: 1 Batch: 1177, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [2.190149, 0.0, 0.0, 0.07911168, 0.11176118, 0.14249292, 0.13892753]]\nEpoch: 1 Batch: 1178, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [2.3133698, 0.0, 0.0, 0.09864817, 0.09877792, 0.19803861, 0.14107037]]\nEpoch: 1 Batch: 1178, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [2.3133698, 0.0, 0.0, 0.09864817, 0.09877792, 0.19803861, 0.14107037]]\nEpoch: 1 Batch: 1179, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [1.5540653, 0.0, 0.0, 0.05609189, 0.07691619, 0.12109614, 0.10288846]]\nEpoch: 1 Batch: 1179, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [1.5540653, 0.0, 0.0, 0.05609189, 0.07691619, 0.12109614, 0.10288846]]\nEpoch: 1 Batch: 1180, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [4.028669, 1.0, 1.0, 0.079421125, 0.08797222, 0.18386328, 0.17087205]]\nEpoch: 1 Batch: 1180, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [4.028669, 1.0, 1.0, 0.079421125, 0.08797222, 0.18386328, 0.17087205]]\nEpoch: 1 Batch: 1181, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [1.014231, 0.0, 0.0, 0.041159417, 0.044108033, 0.08345066, 0.07810586]]\nEpoch: 1 Batch: 1181, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [1.014231, 0.0, 0.0, 0.041159417, 0.044108033, 0.08345066, 0.07810586]]\nEpoch: 1 Batch: 1182, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [1.317082, 0.0, 0.0, 0.048282698, 0.06111751, 0.10479289, 0.11828693]]\nEpoch: 1 Batch: 1182, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [1.317082, 0.0, 0.0, 0.048282698, 0.06111751, 0.10479289, 0.11828693]]\nEpoch: 1 Batch: 1183, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [1.288521, 0.0, 0.0, 0.060405783, 0.049290672, 0.10256615, 0.08899027]]\nEpoch: 1 Batch: 1183, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [1.288521, 0.0, 0.0, 0.060405783, 0.049290672, 0.10256615, 0.08899027]]\nEpoch: 1 Batch: 1184, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [1.5537558, 0.0, 0.0, 0.06074262, 0.071171224, 0.12024724, 0.11436994]]\nEpoch: 1 Batch: 1184, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [1.5537558, 0.0, 0.0, 0.06074262, 0.071171224, 0.12024724, 0.11436994]]\nEpoch: 1 Batch: 1185, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [1.096201, 0.0, 0.0, 0.04546114, 0.046608653, 0.09220908, 0.083293885]]\nEpoch: 1 Batch: 1185, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [1.096201, 0.0, 0.0, 0.04546114, 0.046608653, 0.09220908, 0.083293885]]\nEpoch: 1 Batch: 1186, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [1.7610772, 0.0, 1.4210855e-14, 0.0661995, 0.08275362, 0.13813075, 0.13341516]]\nEpoch: 1 Batch: 1186, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [1.7610772, 0.0, 1.4210855e-14, 0.0661995, 0.08275362, 0.13813075, 0.13341516]]\nEpoch: 1 Batch: 1187, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [0.9854265, 0.0, 0.0, 0.038345776, 0.044937, 0.08119074, 0.07140792]]\nEpoch: 1 Batch: 1187, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [0.9854265, 0.0, 0.0, 0.038345776, 0.044937, 0.08119074, 0.07140792]]\nEpoch: 1 Batch: 1188, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [3.9822247, 1.0, 1.0, 0.08079238, 0.086647816, 0.15785727, 0.14996552]]\nEpoch: 1 Batch: 1188, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [3.9822247, 1.0, 1.0, 0.08079238, 0.086647816, 0.15785727, 0.14996552]]\nEpoch: 1 Batch: 1189, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [1.547289, 0.0, 1.4210855e-14, 0.06577472, 0.06526493, 0.120064676, 0.11682785]]\nEpoch: 1 Batch: 1189, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [1.547289, 0.0, 1.4210855e-14, 0.06577472, 0.06526493, 0.120064676, 0.11682785]]\nEpoch: 1 Batch: 1190, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [1.3275331, 0.0, 0.0, 0.05083569, 0.060110874, 0.10829203, 0.10977553]]\nEpoch: 1 Batch: 1190, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [1.3275331, 0.0, 0.0, 0.05083569, 0.060110874, 0.10829203, 0.10977553]]\nEpoch: 1 Batch: 1191, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [2.2818234, 0.0, 0.0, 0.09756684, 0.098124206, 0.17004187, 0.15487088]]\nEpoch: 1 Batch: 1191, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [2.2818234, 0.0, 0.0, 0.09756684, 0.098124206, 0.17004187, 0.15487088]]\nEpoch: 1 Batch: 1192, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [1.8670025, 0.0, 0.0, 0.07337619, 0.084373534, 0.14170346, 0.14780177]]\nEpoch: 1 Batch: 1192, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [1.8670025, 0.0, 0.0, 0.07337619, 0.084373534, 0.14170346, 0.14780177]]\nEpoch: 1 Batch: 1193, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [1.9402378, 0.0, 0.0, 0.07448081, 0.089964546, 0.14727889, 0.1485053]]\nEpoch: 1 Batch: 1193, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [1.9402378, 0.0, 0.0, 0.07448081, 0.089964546, 0.14727889, 0.1485053]]\nEpoch: 1 Batch: 1194, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [2.1584191, 0.0, 0.0, 0.087163985, 0.0971631, 0.15373708, 0.16141129]]\nEpoch: 1 Batch: 1194, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [2.1584191, 0.0, 0.0, 0.087163985, 0.0971631, 0.15373708, 0.16141129]]\nEpoch: 1 Batch: 1195, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [1.2381986, 0.0, 0.0, 0.055708222, 0.04894598, 0.09718393, 0.09447262]]\nEpoch: 1 Batch: 1195, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [1.2381986, 0.0, 0.0, 0.055708222, 0.04894598, 0.09718393, 0.09447262]]\nEpoch: 1 Batch: 1196, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [2.0866578, 0.0, 0.0, 0.07390471, 0.10077168, 0.1397544, 0.20013955]]\nEpoch: 1 Batch: 1196, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [2.0866578, 0.0, 0.0, 0.07390471, 0.10077168, 0.1397544, 0.20013955]]\nEpoch: 1 Batch: 1197, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [2.2040706, 0.0, 0.0, 0.08730265, 0.10375911, 0.1376423, 0.15581055]]\nEpoch: 1 Batch: 1197, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [2.2040706, 0.0, 0.0, 0.08730265, 0.10375911, 0.1376423, 0.15581055]]\nEpoch: 1 Batch: 1198, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [1.9497099, 0.0, 0.0, 0.08384026, 0.07185304, 0.22863324, 0.16414368]]\nEpoch: 1 Batch: 1198, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [1.9497099, 0.0, 0.0, 0.08384026, 0.07185304, 0.22863324, 0.16414368]]\nEpoch: 1 Batch: 1199, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [2.2262986, 0.0, 0.0, 0.07733838, 0.110891685, 0.17113158, 0.17286624]]\nEpoch: 1 Batch: 1199, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [2.2262986, 0.0, 0.0, 0.07733838, 0.110891685, 0.17113158, 0.17286624]]\nEpoch: 1 Batch: 1200, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [1.6145173, 0.0, 0.0, 0.055137932, 0.08225374, 0.100144304, 0.14045627]]\nEpoch: 1 Batch: 1200, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [1.6145173, 0.0, 0.0, 0.055137932, 0.08225374, 0.100144304, 0.14045627]]\nImage_A shape: (64, 64, 3)\nfake_B shape: (64, 64, 3)\nreconstructed_A shape: (64, 64, 3)\nEpoch: 1 Batch: 1201, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [2.066894, 0.0, 0.0, 0.08559537, 0.09142915, 0.13927907, 0.15736984]]\nEpoch: 1 Batch: 1201, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [2.066894, 0.0, 0.0, 0.08559537, 0.09142915, 0.13927907, 0.15736984]]\nEpoch: 1 Batch: 1202, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [1.8129832, 0.0, 0.0, 0.07392279, 0.07887373, 0.15151297, 0.13350496]]\nEpoch: 1 Batch: 1202, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [1.8129832, 0.0, 0.0, 0.07392279, 0.07887373, 0.15151297, 0.13350496]]\nEpoch: 1 Batch: 1203, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [1.9763275, 0.0, 0.0, 0.084391735, 0.08408156, 0.15167376, 0.13992082]]\nEpoch: 1 Batch: 1203, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [1.9763275, 0.0, 0.0, 0.084391735, 0.08408156, 0.15167376, 0.13992082]]\nEpoch: 1 Batch: 1204, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [1.5303587, 0.0, 0.0, 0.0596228, 0.070394814, 0.10165826, 0.12852433]]\nEpoch: 1 Batch: 1204, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [1.5303587, 0.0, 0.0, 0.0596228, 0.070394814, 0.10165826, 0.12852433]]\nEpoch: 1 Batch: 1205, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [1.2790865, 0.0, 0.0, 0.050773952, 0.05639691, 0.099872865, 0.107504986]]\nEpoch: 1 Batch: 1205, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [1.2790865, 0.0, 0.0, 0.050773952, 0.05639691, 0.099872865, 0.107504986]]\nEpoch: 1 Batch: 1206, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [2.208743, 0.0, 0.0, 0.094955824, 0.091341004, 0.15682316, 0.18895149]]\nEpoch: 1 Batch: 1206, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [2.208743, 0.0, 0.0, 0.094955824, 0.091341004, 0.15682316, 0.18895149]]\nEpoch: 1 Batch: 1207, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [2.142226, 0.0, 0.0, 0.10703657, 0.07596129, 0.18309467, 0.12915275]]\nEpoch: 1 Batch: 1207, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [2.142226, 0.0, 0.0, 0.10703657, 0.07596129, 0.18309467, 0.12915275]]\nEpoch: 1 Batch: 1208, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [1.3218541, 0.0, 0.0, 0.046565782, 0.06040421, 0.11406556, 0.13808863]]\nEpoch: 1 Batch: 1208, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [1.3218541, 0.0, 0.0, 0.046565782, 0.06040421, 0.11406556, 0.13808863]]\nEpoch: 1 Batch: 1209, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [3.0497847, 1.0, 1.0, 0.0403635, 0.046142567, 0.092510596, 0.09221323]]\nEpoch: 1 Batch: 1209, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [3.0497847, 1.0, 1.0, 0.0403635, 0.046142567, 0.092510596, 0.09221323]]\nEpoch: 1 Batch: 1210, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [1.3481679, 0.0, 0.0, 0.051052917, 0.060235493, 0.10013508, 0.13514881]]\nEpoch: 1 Batch: 1210, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [1.3481679, 0.0, 0.0, 0.051052917, 0.060235493, 0.10013508, 0.13514881]]\nEpoch: 1 Batch: 1211, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [1.3257246, 0.0, 0.0, 0.052602407, 0.060144506, 0.09407385, 0.1041816]]\nEpoch: 1 Batch: 1211, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [1.3257246, 0.0, 0.0, 0.052602407, 0.060144506, 0.09407385, 0.1041816]]\nEpoch: 1 Batch: 1212, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [2.3347945, 0.0, 0.0, 0.08313149, 0.11441015, 0.15565677, 0.2037214]]\nEpoch: 1 Batch: 1212, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [2.3347945, 0.0, 0.0, 0.08313149, 0.11441015, 0.15565677, 0.2037214]]\nEpoch: 1 Batch: 1213, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [2.1857522, 0.0, 0.0, 0.08938157, 0.097838305, 0.14489917, 0.16865425]]\nEpoch: 1 Batch: 1213, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [2.1857522, 0.0, 0.0, 0.08938157, 0.097838305, 0.14489917, 0.16865425]]\nEpoch: 1 Batch: 1214, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [1.9928545, 0.0, 0.0, 0.072396405, 0.093807176, 0.14130954, 0.1895093]]\nEpoch: 1 Batch: 1214, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [1.9928545, 0.0, 0.0, 0.072396405, 0.093807176, 0.14130954, 0.1895093]]\nEpoch: 1 Batch: 1215, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [1.981294, 0.0, 0.0, 0.07274292, 0.09763013, 0.12779185, 0.14977172]]\nEpoch: 1 Batch: 1215, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [1.981294, 0.0, 0.0, 0.07274292, 0.09763013, 0.12779185, 0.14977172]]\nEpoch: 1 Batch: 1216, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [2.1554568, 0.0, 3.1974423e-12, 0.08382015, 0.10084923, 0.14061327, 0.16814952]]\nEpoch: 1 Batch: 1216, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [2.1554568, 0.0, 3.1974423e-12, 0.08382015, 0.10084923, 0.14061327, 0.16814952]]\nEpoch: 1 Batch: 1217, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [0.9007209, 0.0, 0.0, 0.033749856, 0.043312203, 0.07471907, 0.055381246]]\nEpoch: 1 Batch: 1217, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [0.9007209, 0.0, 0.0, 0.033749856, 0.043312203, 0.07471907, 0.055381246]]\nEpoch: 1 Batch: 1218, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [2.85025, 0.0, 0.0, 0.105246335, 0.13674814, 0.20794615, 0.22235927]]\nEpoch: 1 Batch: 1218, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [2.85025, 0.0, 0.0, 0.105246335, 0.13674814, 0.20794615, 0.22235927]]\nEpoch: 1 Batch: 1219, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [1.2724392, 0.0, 0.0, 0.056296427, 0.054480173, 0.07492564, 0.0897477]]\nEpoch: 1 Batch: 1219, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [1.2724392, 0.0, 0.0, 0.056296427, 0.054480173, 0.07492564, 0.0897477]]\nEpoch: 1 Batch: 1220, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [1.5359983, 0.0, 0.0, 0.059026547, 0.07459603, 0.08641515, 0.11335747]]\nEpoch: 1 Batch: 1220, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [1.5359983, 0.0, 0.0, 0.059026547, 0.07459603, 0.08641515, 0.11335747]]\nEpoch: 1 Batch: 1221, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [2.2913735, 0.0, 0.0, 0.09663318, 0.10332261, 0.11450692, 0.17730862]]\nEpoch: 1 Batch: 1221, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [2.2913735, 0.0, 0.0, 0.09663318, 0.10332261, 0.11450692, 0.17730862]]\nEpoch: 1 Batch: 1222, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [1.4632794, 0.0, 0.0, 0.06008369, 0.06691088, 0.10538752, 0.08794619]]\nEpoch: 1 Batch: 1222, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [1.4632794, 0.0, 0.0, 0.06008369, 0.06691088, 0.10538752, 0.08794619]]\nEpoch: 1 Batch: 1223, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [1.9319403, 0.0, 0.0, 0.10057469, 0.066070735, 0.13376342, 0.13172269]]\nEpoch: 1 Batch: 1223, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [1.9319403, 0.0, 0.0, 0.10057469, 0.066070735, 0.13376342, 0.13172269]]\nEpoch: 1 Batch: 1224, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [0.87504554, 0.0, 0.0, 0.039970487, 0.031372268, 0.08881901, 0.07279898]]\nEpoch: 1 Batch: 1224, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [0.87504554, 0.0, 0.0, 0.039970487, 0.031372268, 0.08881901, 0.07279898]]\nEpoch: 1 Batch: 1225, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [1.4280871, 0.0, 0.0, 0.064653665, 0.058396503, 0.089759775, 0.10782569]]\nEpoch: 1 Batch: 1225, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [1.4280871, 0.0, 0.0, 0.064653665, 0.058396503, 0.089759775, 0.10782569]]\nEpoch: 1 Batch: 1226, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [1.2915202, 0.0, 0.0, 0.049357865, 0.06244091, 0.07900801, 0.09452447]]\nEpoch: 1 Batch: 1226, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [1.2915202, 0.0, 0.0, 0.049357865, 0.06244091, 0.07900801, 0.09452447]]\nEpoch: 1 Batch: 1227, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [1.5397578, 0.0, 0.0, 0.07350474, 0.059712484, 0.108341396, 0.09924423]]\nEpoch: 1 Batch: 1227, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [1.5397578, 0.0, 0.0, 0.07350474, 0.059712484, 0.108341396, 0.09924423]]\nEpoch: 1 Batch: 1228, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [1.9876585, 0.0, 0.0, 0.09296666, 0.07646634, 0.15035136, 0.14297707]]\nEpoch: 1 Batch: 1228, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [1.9876585, 0.0, 0.0, 0.09296666, 0.07646634, 0.15035136, 0.14297707]]\nEpoch: 1 Batch: 1229, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [2.425747, 0.0, 0.0, 0.093853205, 0.10947241, 0.17059615, 0.22189471]]\nEpoch: 1 Batch: 1229, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [2.425747, 0.0, 0.0, 0.093853205, 0.10947241, 0.17059615, 0.22189471]]\nEpoch: 1 Batch: 1230, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [0.8346866, 0.0, 0.0, 0.040613286, 0.02898701, 0.08714638, 0.051537216]]\nEpoch: 1 Batch: 1230, [Discriminator_B :: Loss: 0.5], [ Generator :: Loss: [0.8346866, 0.0, 0.0, 0.040613286, 0.02898701, 0.08714638, 0.051537216]]\nEpoch: 1, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [0.8346866, 0.0, 0.0, 0.040613286, 0.02898701, 0.08714638, 0.051537216]]\nEpoch: 1, [Discriminator_A :: Loss: 0.5], [ Generator :: Loss: [0.8346866, 0.0, 0.0, 0.040613286, 0.02898701, 0.08714638, 0.051537216]]\n"
    }
   ],
   "source": [
    "# Command Line Argument Method\n",
    "HEIGHT  = 64\n",
    "WIDTH   = 64\n",
    "CHANNEL = 3\n",
    "EPOCHS = 5\n",
    "#EPOCHS = 2\n",
    "# our batch in this base is only a single image.\n",
    "BATCH = 1\n",
    "CHECKPOINT = 200\n",
    "\n",
    "TRAIN_PATH_A = \"./data/summer2winter_yosemite/trainA/\"\n",
    "TRAIN_PATH_B = \"./data/summer2winter_yosemite/trainA/\"\n",
    "TEST_PATH_A = \"./data/summer2winter_yosemite/trainA/\"\n",
    "TEST_PATH_B = \"./data/summer2winter_yosemite/trainA/\"\n",
    "\n",
    "trainer = Trainer(height=HEIGHT,width=WIDTH,epochs =EPOCHS,\\\n",
    "                 batch=BATCH,\\\n",
    "                 checkpoint=CHECKPOINT,\\\n",
    "                 train_data_path_A=TRAIN_PATH_A,\\\n",
    "                 train_data_path_B=TRAIN_PATH_B,\\\n",
    "                 test_data_path_A=TEST_PATH_A,\\\n",
    "                 test_data_path_B=TEST_PATH_B,\\\n",
    "                 lambda_cycle=10.0,\\\n",
    "                 lambda_id=1.0)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_dd4kKqbsOYc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "style_transferring_of_image_using_cycle_gan-on-colab-with-summer2winter_yosemite-dataset.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}